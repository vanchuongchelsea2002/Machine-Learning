
import streamlit as st
import os
import cv2
import numpy as np
import pandas as pd
import pickle
import seaborn as sns
import random
import struct
import altair
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
import mlflow
from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from PIL import Image
from collections import Counter
from mlflow.tracking import MlflowClient
def run_ClusteringMinst_app():
    @st.cache_data  # LÆ°u cache Ä‘á»ƒ trÃ¡nh load láº¡i dá»¯ liá»‡u má»—i láº§n cháº¡y láº¡i Streamlit
    def get_sampled_pixels(images, sample_size=100_000):
        return np.random.choice(images.flatten(), sample_size, replace=False)

    @st.cache_data  # Cache danh sÃ¡ch áº£nh ngáº«u nhiÃªn
    def get_random_indices(num_images, total_images):
        return np.random.randint(0, total_images, size=num_images)

    # Cáº¥u hÃ¬nh Streamlit
    # st.set_page_config(page_title="PhÃ¢n loáº¡i áº£nh", layout="wide")
    # Äá»‹nh nghÄ©a hÃ m Ä‘á»ƒ Ä‘á»c file .idx
    def load_mnist_images(filename):
        with open(filename, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
        return images

    def load_mnist_labels(filename):
        with open(filename, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            labels = np.fromfile(f, dtype=np.uint8)
        return labels

    mlflow_tracking_uri = st.secrets["MLFLOW_TRACKING_URI"]
    mlflow_username = st.secrets["MLFLOW_TRACKING_USERNAME"]
    mlflow_password = st.secrets["MLFLOW_TRACKING_PASSWORD"]
    
    # Thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng
    os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
    os.environ["MLFLOW_TRACKING_USERNAME"] = mlflow_username
    os.environ["MLFLOW_TRACKING_PASSWORD"] = mlflow_password
    
    # Thiáº¿t láº­p MLflow (Äáº·t sau khi mlflow_tracking_uri Ä‘Ã£ cÃ³ giÃ¡ trá»‹)
    mlflow.set_tracking_uri(mlflow_tracking_uri)



    # Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n Ä‘áº¿n cÃ¡c file MNIST
    # dataset_path = r"C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App"
    dataset_path = os.path.dirname(os.path.abspath(__file__)) 
    train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
    train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
    test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
    test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

    if "train_images" not in st.session_state:
            st.session_state.train_images = load_mnist_images(train_images_path)
            st.session_state.train_labels = load_mnist_labels(train_labels_path)
            st.session_state.test_images = load_mnist_images(test_images_path)
            st.session_state.test_labels = load_mnist_labels(test_labels_path)
    # Táº£i dá»¯ liá»‡u
    train_images = load_mnist_images(train_images_path)
    train_labels = load_mnist_labels(train_labels_path)
    test_images = load_mnist_images(test_images_path)
    test_labels = load_mnist_labels(test_labels_path)

    

    # Giao diá»‡n Streamlit
    st.title("ğŸ“¸ MNIST Clustering")
    tabs = st.tabs([
            "Táº­p dá»¯ liá»‡u",
            "Xá»­ lÃ­ dá»¯ liá»‡u",
            "ThÃ´ng tin",
            "Huáº¥n luyá»‡n mÃ´ hÃ¬nh",
            "ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh",
            "ThÃ´ng tin & Mlflow",
    ])
    tab_info, tab_load,tab_note, tab_preprocess, tab_split ,tab_mlflow= tabs
    with tab_info:
        with st.expander("**ThÃ´ng tin dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                **MNIST** lÃ  phiÃªn báº£n Ä‘Æ°á»£c chá»‰nh sá»­a tá»« bá»™ dá»¯ liá»‡u **NIST gá»‘c** cá»§a Viá»‡n TiÃªu chuáº©n vÃ  CÃ´ng nghá»‡ Quá»‘c gia Hoa Ká»³.  
                Bá»™ dá»¯ liá»‡u ban Ä‘áº§u gá»“m cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« **nhÃ¢n viÃªn bÆ°u Ä‘iá»‡n** vÃ  **há»c sinh trung há»c**.  

                CÃ¡c nhÃ  nghiÃªn cá»©u **Yann LeCun, Corinna Cortes, vÃ  Christopher Burges** Ä‘Ã£ xá»­ lÃ½, chuáº©n hÃ³a vÃ  chuyá»ƒn Ä‘á»•i bá»™ dá»¯ liá»‡u nÃ y thÃ nh **MNIST**  
                Ä‘á»ƒ dá»… dÃ ng sá»­ dá»¥ng hÆ¡n cho cÃ¡c bÃ i toÃ¡n nháº­n dáº¡ng chá»¯ sá»‘ viáº¿t tay.
                '''
            )
            # Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u
        with st.expander("**Äáº·c Ä‘iá»ƒm cá»§a bá»™ dá»¯ liá»‡u**", expanded=True):
            st.markdown(
                '''
                - **Sá»‘ lÆ°á»£ng áº£nh:** 70.000 áº£nh chá»¯ sá»‘ viáº¿t tay  
                - **KÃ­ch thÆ°á»›c áº£nh:** Má»—i áº£nh cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel  
                - **CÆ°á»ng Ä‘á»™ Ä‘iá»ƒm áº£nh:** Tá»« 0 (mÃ u Ä‘en) Ä‘áº¿n 255 (mÃ u tráº¯ng)  
                - **Dá»¯ liá»‡u nhÃ£n:** Má»—i áº£nh Ä‘i kÃ¨m vá»›i má»™t nhÃ£n sá»‘ tá»« 0 Ä‘áº¿n 9  
                '''
            )
            st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh huáº¥n luyá»‡n: `{train_images.shape[0]}`")
            st.write(f"ğŸ” Sá»‘ lÆ°á»£ng áº£nh kiá»ƒm tra: `{test_images.shape[0]}`")


        with st.expander("**Hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9 trong táº­p huáº¥n luyá»‡n**", expanded=True):
            label_counts = pd.Series(train_labels).value_counts().sort_index()
            # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u dÆ°á»›i biá»ƒu Ä‘á»“
            df_counts = pd.DataFrame({"Chá»¯ sá»‘": label_counts.index, "Sá»‘ lÆ°á»£ng máº«u": label_counts.values})
            st.dataframe(df_counts)
            num_images = 10
            random_indices = random.sample(range(len(train_images)), num_images)
            fig, axes = plt.subplots(1, num_images, figsize=(15, 5))
            st.write("**Má»™t sá»‘ áº£nh vÃ­ dá»¥:**")
            for ax, idx in zip(axes, random_indices):
                ax.imshow(train_images[idx], cmap='gray')
                ax.axis("off")
                ax.set_title(f"Label: {train_labels[idx]}")

            st.pyplot(fig)

        with st.expander("**Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u**", expanded=True):    
                # Kiá»ƒm tra hÃ¬nh dáº¡ng cá»§a táº­p dá»¯ liá»‡u
            st.write("ğŸ” HÃ¬nh dáº¡ng táº­p huáº¥n luyá»‡n:", train_images.shape)
            st.write("ğŸ” HÃ¬nh dáº¡ng táº­p kiá»ƒm tra:", test_images.shape)
            # Kiá»ƒm tra xem cÃ³ giÃ¡ trá»‹ pixel nÃ o ngoÃ i pháº¡m vi 0-255 khÃ´ng
            if (train_images.min() < 0) or (train_images.max() > 255):
                st.error("âš ï¸ Cáº£nh bÃ¡o: CÃ³ giÃ¡ trá»‹ pixel ngoÃ i pháº¡m vi 0-255!")
            else:
                st.success("âœ… Dá»¯ liá»‡u pixel há»£p lá»‡ (0 - 255).")

            # Chuáº©n hÃ³a dá»¯ liá»‡u
            train_images = train_images.astype("float32") / 255.0
            test_images = test_images.astype("float32") / 255.0

            # Hiá»ƒn thá»‹ thÃ´ng bÃ¡o sau khi chuáº©n hÃ³a
            st.success("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a vá» khoáº£ng [0,1].")

            # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a (dáº¡ng sá»‘)
            num_samples = 5  # Sá»‘ lÆ°á»£ng máº«u hiá»ƒn thá»‹
            df_normalized = pd.DataFrame(train_images[:num_samples].reshape(num_samples, -1))  

            st.write("**Báº£ng dá»¯ liá»‡u sau khi chuáº©n hÃ³a**")
            st.dataframe(df_normalized)

            
            sample_size = 10_000  
            pixel_sample = np.random.choice(train_images.flatten(), sample_size, replace=False)



    with tab_load:
        with st.expander("**Xá»­ lÃ½ dá»¯ liá»‡u**", expanded=True):    
            # Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u thÃ nh vector 1 chiá»u
            X_train = st.session_state.train_images.reshape(st.session_state.train_images.shape[0], -1)
            X_test = st.session_state.test_images.reshape(st.session_state.test_images.shape[0], -1)
            y_train = train_labels
            y_test = test_labels

            # Chá»n tá»· lá»‡ táº­p validation
            val_size = st.slider("ğŸ”¹ **Chá»n tá»· lá»‡ táº­p validation (%)**", min_value=10, max_value=50, value=20, step=5) / 100

            # Chá»n tá»· lá»‡ táº­p kiá»ƒm tra (test)
            test_size = st.slider("ğŸ”¹ **Chá»n tá»· lá»‡ táº­p kiá»ƒm tra (%)**", min_value=10, max_value=40, value=20, step=5) / 100

            # Chia táº­p train ban Ä‘áº§u thÃ nh train + validation + test
            X_train, X_temp, y_train, y_temp = train_test_split(X_train, y_train, test_size=(val_size + test_size), random_state=42)

            # Tiáº¿p tá»¥c chia X_temp thÃ nh validation vÃ  test theo tá»· lá»‡ Ä‘Ã£ chá»n
            X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_size / (val_size + test_size)), random_state=42)

            st.session_state.X_train = X_train
            st.session_state.X_val = X_val
            st.session_state.X_test = X_test


            st.write("âœ… Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ vÃ  chia tÃ¡ch.")
            st.write(f"ğŸ”¹ **KÃ­ch thÆ°á»›c táº­p huáº¥n luyá»‡n**: `{X_train.shape}`")
            st.write(f"ğŸ”¹ **KÃ­ch thÆ°á»›c táº­p validation**: `{X_val.shape}`")
            st.write(f"ğŸ”¹ **KÃ­ch thÆ°á»›c táº­p kiá»ƒm tra**: `{X_test.shape}`")

            # Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i nhÃ£n trong táº­p huáº¥n luyá»‡n
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.barplot(x=list(Counter(y_train).keys()), y=list(Counter(y_train).values()), palette="Blues", ax=ax)
            ax.set_title("PhÃ¢n phá»‘i nhÃ£n trong táº­p huáº¥n luyá»‡n")
            ax.set_xlabel("NhÃ£n")
            ax.set_ylabel("Sá»‘ lÆ°á»£ng")
            st.pyplot(fig)

    with tab_note:
        with st.expander("**ThÃ´ng tin mÃ´ hÃ¬nh**", expanded=True):
            # Chá»n mÃ´ hÃ¬nh
            model_option1 = st.selectbox("Chá»n mÃ´ hÃ¬nh", ["K-Means", "DBSCAN"])
            
            if model_option1 == "K-Means":
                st.markdown("## ğŸ”¹ K-Means Clustering")
                st.markdown("---")

                st.markdown("**KhÃ¡i niá»‡m**")
                st.write("""
                - **K-Means** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m chia dá»¯ liá»‡u thÃ nh $K$ nhÃ³m dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm vÃ  tÃ¢m cá»¥m.
                - Thuáº­t toÃ¡n tÃ¬m cÃ¡ch **tá»‘i thiá»ƒu hÃ³a tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch** giá»¯a cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u vÃ  tÃ¢m cá»¥m (**WCSS**).
                """)

                st.markdown("### ğŸ”„ **Quy trÃ¬nh hoáº¡t Ä‘á»™ng**")
                st.write("""
                1. Chá»n ngáº«u nhiÃªn $K$ tÃ¢m cá»¥m ban Ä‘áº§u.
                2. GÃ¡n má»—i Ä‘iá»ƒm vÃ o cá»¥m gáº§n nháº¥t dá»±a trÃªn khoáº£ng cÃ¡ch.
                3. Cáº­p nháº­t láº¡i tÃ¢m cá»¥m báº±ng trung bÃ¬nh cá»§a cÃ¡c Ä‘iá»ƒm trong cá»¥m.
                4. Láº·p láº¡i cho Ä‘áº¿n khi thuáº­t toÃ¡n há»™i tá»¥.
                """)

                st.markdown("### âš™ï¸ **CÃ¡c tham sá»‘ chÃ­nh**")
                st.write("""
                - **Sá»‘ cá»¥m $K$**: Sá»‘ lÆ°á»£ng cá»¥m cáº§n phÃ¢n loáº¡i.
                - **init method**:
                    - `"random"`: Chá»n tÃ¢m cá»¥m ngáº«u nhiÃªn.
                    - `"k-means++"`: Chá»n tÃ¢m cá»¥m thÃ´ng minh hÆ¡n Ä‘á»ƒ tÄƒng tá»‘c há»™i tá»¥.
                - **max_iter**: Sá»‘ láº§n láº·p tá»‘i Ä‘a trÆ°á»›c khi thuáº­t toÃ¡n dá»«ng.
                """)
                st.markdown("### ğŸ¤” **Táº¡i sao cáº§n K-Means++?**")
                st.write("""
                - Trong **K-Means**, náº¿u chá»n tÃ¢m cá»¥m ban Ä‘áº§u **ngáº«u nhiÃªn khÃ´ng tá»‘t**, thuáº­t toÃ¡n cÃ³ thá»ƒ:
                    - Há»™i tá»¥ cháº­m hoáº·c máº¯c káº¹t vÃ o nghiá»‡m kÃ©m tá»‘i Æ°u.
                    - Táº¡o cá»¥m khÃ´ng cÃ¢n Ä‘á»‘i.
                    - Nháº¡y cáº£m vá»›i outlier.
                - **K-Means++** giÃºp chá»n tÃ¢m cá»¥m **má»™t cÃ¡ch thÃ´ng minh hÆ¡n**, giÃºp thuáº­t toÃ¡n **há»™i tá»¥ nhanh hÆ¡n vÃ  á»•n Ä‘á»‹nh hÆ¡n**.
                - **K-Means++** lÃ  má»™t cáº£i tiáº¿n cá»§a thuáº­t toÃ¡n K-Means nháº±m chá»n tÃ¢m cá»¥m ban Ä‘áº§u má»™t cÃ¡ch thÃ´ng minh hÆ¡n, giÃºp tÄƒng Ä‘á»™ á»•n Ä‘á»‹nh vÃ  giáº£m nguy cÆ¡ há»™i tá»¥ vÃ o nghiá»‡m kÃ©m tá»‘i Æ°u.
                """)

                st.markdown("### âœ… **Äiá»u kiá»‡n há»™i tá»¥**")
                st.write("""
                - TÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i giá»¯a cÃ¡c vÃ²ng láº·p.
                - GÃ¡n cá»¥m cá»§a cÃ¡c Ä‘iá»ƒm khÃ´ng thay Ä‘á»•i.
                - Sá»‘ láº§n láº·p Ä‘áº¡t `max_iter`.
                - Tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch khÃ´ng giáº£m Ä‘Ã¡ng ká»ƒ.
                """)

                st.markdown("### ğŸ‘ **Æ¯u Ä‘iá»ƒm**")
                st.write("""
                - Dá»… hiá»ƒu, dá»… triá»ƒn khai.
                - Hiá»‡u suáº¥t cao vá»›i dá»¯ liá»‡u lá»›n.
                """)

                st.markdown("### âš ï¸ **NhÆ°á»£c Ä‘iá»ƒm**")
                st.write("""
                - Cáº§n chá»n trÆ°á»›c sá»‘ cá»¥m $K$.
                - Nháº¡y cáº£m vá»›i nhiá»…u vÃ  outlier.
                - KhÃ´ng hiá»‡u quáº£ náº¿u cá»¥m cÃ³ hÃ¬nh dáº¡ng báº¥t thÆ°á»ng.
                """)

            elif model_option1 == "DBSCAN":
                st.markdown("## ğŸ”¹ DBSCAN (Density-Based Clustering)")
                st.markdown("---")

                st.markdown("**KhÃ¡i niá»‡m**")
                st.write("""
                - DBSCAN lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™, hoáº¡t Ä‘á»™ng tá»‘t vá»›i dá»¯ liá»‡u cÃ³ hÃ¬nh dáº¡ng cá»¥m phá»©c táº¡p.
                - KhÃ´ng cáº§n chá»n sá»‘ cá»¥m trÆ°á»›c, mÃ  dá»±a vÃ o máº­t Ä‘á»™ dá»¯ liá»‡u.
                """)

                st.markdown("### ğŸ”„ **Quy trÃ¬nh hoáº¡t Ä‘á»™ng**")
                st.write("""
                1. Chá»n má»™t Ä‘iá»ƒm dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c phÃ¢n cá»¥m.
                2. Náº¿u trong bÃ¡n kÃ­nh `eps` cÃ³ Ã­t nháº¥t `min_samples` Ä‘iá»ƒm, thuáº­t toÃ¡n táº¡o má»™t cá»¥m má»›i.
                3. Má»Ÿ rá»™ng cá»¥m báº±ng cÃ¡ch tÃ¬m Ä‘iá»ƒm gáº§n ká» cÃ³ máº­t Ä‘á»™ cao.
                4. Äiá»ƒm nÃ o khÃ´ng thuá»™c cá»¥m nÃ o Ä‘Æ°á»£c coi lÃ  **nhiá»…u (outlier)**.
                """)

                st.markdown("### âš™ï¸ **CÃ¡c tham sá»‘ chÃ­nh**")
                st.write("""
                - **Epsilon (`eps`)**: BÃ¡n kÃ­nh lÃ¢n cáº­n.
                - **min_samples**: Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu Ä‘á»ƒ táº¡o cá»¥m.
                - **max_iter**: Sá»‘ láº§n láº·p tá»‘i Ä‘a trÆ°á»›c khi thuáº­t toÃ¡n dá»«ng.
                - **metric**: CÃ¡ch tÃ­nh khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm:
                    - `"euclidean"`: Khoáº£ng cÃ¡ch Euclid.
                    - `"manhattan"`: Khoáº£ng cÃ¡ch Manhattan.
                    - `"cosine"`: Khoáº£ng cÃ¡ch Cosine.
                """)

                st.markdown("### ğŸ‘ **Æ¯u Ä‘iá»ƒm**")
                st.write("""
                - KhÃ´ng cáº§n chá»n sá»‘ cá»¥m trÆ°á»›c.
                - Xá»­ lÃ½ tá»‘t dá»¯ liá»‡u cÃ³ hÃ¬nh dáº¡ng cá»¥m phá»©c táº¡p.
                - Tá»± Ä‘á»™ng phÃ¡t hiá»‡n outlier.
                """)

                st.markdown("### âš ï¸ **NhÆ°á»£c Ä‘iá»ƒm**")
                st.write("""
                - Nháº¡y cáº£m vá»›i giÃ¡ trá»‹ `eps` vÃ  `min_samples`.
                - Hiá»‡u suáº¥t giáº£m vá»›i dá»¯ liá»‡u cÃ³ máº­t Ä‘á»™ khÃ´ng Ä‘á»“ng nháº¥t.
                - KhÃ´ng hiá»‡u quáº£ vá»›i dá»¯ liá»‡u cÃ³ sá»‘ chiá»u cao.
                """)


    with tab_preprocess:
        with st.expander("**Ká»¹ thuáº­t phÃ¢n cá»¥m**", expanded=True):    
            st.write("***PhÃ¢n cá»¥m dá»¯ liá»‡u***")

            if "X_train" in st.session_state and "X_val" in st.session_state and "X_test" in st.session_state:
                # Láº¥y dá»¯ liá»‡u tá»« session_state
                X_train = st.session_state.X_train
                X_val = st.session_state.X_val
                X_test = st.session_state.X_test
                # Chuáº©n hÃ³a dá»¯ liá»‡u
                    # Chuáº©n hÃ³a dá»¯ liá»‡u
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_val_scaled = scaler.transform(X_val)
                X_test_scaled = scaler.transform(X_test)

                    # Giáº£m chiá»u báº±ng PCA (2D) Ä‘á»ƒ trá»±c quan hÃ³a 
                pca = PCA(n_components=2)
                X_train_pca = pca.fit_transform(X_train_scaled)
                    
                    # Chá»n phÆ°Æ¡ng phÃ¡p phÃ¢n cá»¥m
                clustering_method = st.selectbox("ğŸ”¹ Chá»n phÆ°Æ¡ng phÃ¡p phÃ¢n cá»¥m:", ["K-means", "DBSCAN"])

                if clustering_method == "K-means":
                    k = st.slider("ğŸ”¸ Sá»‘ cá»¥m (K-means)", min_value=2, max_value=20, value=10)

                    init_method = st.selectbox("ğŸ”¸ PhÆ°Æ¡ng phÃ¡p khá»Ÿi táº¡o", ["k-means++", "random"])
                    max_iter = st.slider("ğŸ”¸ Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a", min_value=100, max_value=500, value=300, step=50)
                    if st.button("ğŸš€ Cháº¡y K-means"):
                        with mlflow.start_run():
                            kmeans = KMeans(n_clusters=k, init=init_method, max_iter=max_iter, random_state=42, n_init=10)
                            labels = kmeans.fit_predict(X_train_pca)

                            mlflow.log_param("algorithm", "K-means")
                            mlflow.log_param("k", k)
                            mlflow.log_param("init_method", init_method)
                            mlflow.log_param("max_iter", max_iter)    

                                # Log káº¿t quáº£: Inertia (tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch)
                            mlflow.log_metric("inertia", kmeans.inertia_)
                                # Log mÃ´ hÃ¬nh K-means
                            mlflow.sklearn.log_model(kmeans, "kmeans_model")


                                # Váº½ biá»ƒu Ä‘á»“ phÃ¢n cá»¥m
                            fig, ax = plt.subplots(figsize=(6, 4))
                            scatter = ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=labels, cmap='tab10', alpha=0.5)
                            ax.set_title(f"K-means vá»›i K={k}")
                            legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
                            ax.add_artist(legend1)
                            st.pyplot(fig)

                            fig.savefig("kmeans_clusters.png")
                            mlflow.log_artifact("kmeans_clusters.png")

                            st.markdown(
                                """
                                ### ğŸ“Œ Giáº£i thÃ­ch biá»ƒu Ä‘á»“ phÃ¢n cá»¥m   
                                - **Má»—i cháº¥m trÃªn Ä‘á»“ thá»‹** ğŸŸ¢ğŸ”µğŸŸ£: Äáº¡i diá»‡n cho má»™t máº«u dá»¯ liá»‡u trong táº­p huáº¥n luyá»‡n (á»Ÿ Ä‘Ã¢y cÃ³ thá»ƒ lÃ  dá»¯ liá»‡u MNIST hoáº·c má»™t táº­p dá»¯ liá»‡u khÃ¡c).  
                                - **MÃ u sáº¯c** ğŸ¨:  
                                    - CÃ¡c mÃ u sáº¯c tÆ°á»£ng trÆ°ng cho cÃ¡c cá»¥m dá»¯ liá»‡u Ä‘Æ°á»£c táº¡o ra bá»Ÿi thuáº­t toÃ¡n K-Means vá»›i K báº±ng sá»‘ cá»¥m Ä‘Æ°á»£c chá»n.  
                                    - CÃ¡c Ä‘iá»ƒm cÃ³ cÃ¹ng mÃ u Ä‘Æ°á»£c nhÃ³m láº¡i vÃ o cÃ¹ng má»™t cá»¥m do K-Means phÃ¢n cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch trong khÃ´ng gian hai chiá»u.  
                                - **Trá»¥c X vÃ  Y** ğŸ“‰:  
                                    - ÄÃ¢y lÃ  hai thÃ nh pháº§n chÃ­nh (principal components) Ä‘Æ°á»£c táº¡o ra báº±ng phÆ°Æ¡ng phÃ¡p PCA (Principal Component Analysis).  
                                    - PCA giÃºp giáº£m chiá»u dá»¯ liá»‡u tá»« nhiá»u chiá»u xuá»‘ng 2 chiá»u Ä‘á»ƒ trá»±c quan hÃ³a.  
                                    - GiÃ¡ trá»‹ trÃªn trá»¥c X vÃ  Y cÃ³ thá»ƒ lÃªn Ä‘áº¿n khoáº£ng Â±30, pháº£n Ã¡nh sá»± phÃ¢n bá»‘ dá»¯ liá»‡u sau khi PCA Ä‘Æ°á»£c Ã¡p dá»¥ng.  
                                - **ChÃº thÃ­ch (legend)** ğŸ·ï¸: Hiá»ƒn thá»‹ cÃ¡c cá»¥m Ä‘Æ°á»£c táº¡o ra.  

                                """
                            )
                        mlflow.end_run()

                elif clustering_method == "DBSCAN":
                    eps = st.slider("ğŸ”¸ Epsilon (DBSCAN)", min_value=0.1, max_value=5.0, value=1.0, step=0.1)
                    max_iter = st.slider("ğŸ”¸ Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a", min_value=100, max_value=500, value=300, step=50)
                    min_samples = st.slider("ğŸ”¸ Min Samples (DBSCAN)", min_value=1, max_value=20, value=5)
                    metric = st.selectbox("ğŸ”¸ Khoáº£ng cÃ¡ch (Metric)", ["euclidean", "manhattan", "cosine"])

                    if st.button("ğŸš€ Cháº¡y DBSCAN"):
                        with mlflow.start_run():
                            dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric=metric)
                            labels = dbscan.fit_predict(X_train_pca)

                            mlflow.log_param("algorithm", "DBSCAN")
                            mlflow.log_param("eps", eps)
                            mlflow.log_param("min_samples", min_samples)
                            mlflow.log_param("metric", metric)

                                # Log sá»‘ lÆ°á»£ng cá»¥m tÃ¬m Ä‘Æ°á»£c (khÃ´ng tÃ­nh noise)
                            num_clusters = len(set(labels)) - (1 if -1 in labels else 0)
                            mlflow.log_metric("num_clusters", num_clusters)

                                # Log mÃ´ hÃ¬nh DBSCAN (LÆ°u Ã½: DBSCAN khÃ´ng cÃ³ model serialization nhÆ° KMeans)
                            mlflow.sklearn.log_model(dbscan, "dbscan_model")

                                # Váº½ biá»ƒu Ä‘á»“ phÃ¢n cá»¥m
                            ffig, ax = plt.subplots(figsize=(6, 4))
                            scatter = ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=labels, cmap='tab10', alpha=0.5)
                            ax.set_title(f"DBSCAN vá»›i eps={eps}, min_samples={min_samples}")
                            legend1 = ax.legend(*scatter.legend_elements(), title="Clusters")
                            ax.add_artist(legend1)
                            st.pyplot(fig)

                            fig.savefig("dbscan_clusters.png")
                            mlflow.log_artifact("dbscan_clusters.png")
                                
                            st.markdown("""
                                ### ğŸ“Œ Giáº£i thÃ­ch biá»ƒu Ä‘á»“ phÃ¢n cá»¥m  
                                - **Má»—i cháº¥m trÃªn Ä‘á»“ thá»‹** ğŸŸ¢ğŸ”µğŸŸ£:  
                                - Má»—i cháº¥m trÃªn Ä‘á»“ thá»‹ biá»ƒu diá»…n má»™t Ä‘iá»ƒm dá»¯ liá»‡u, Ä‘Æ°á»£c tÃ´ mÃ u theo cá»¥m mÃ  thuáº­t toÃ¡n xÃ¡c Ä‘á»‹nh.  
                                - Trá»¥c X vÃ  Y lÃ  khÃ´ng gian giáº£m chiá»u (cÃ³ thá»ƒ báº±ng PCA hoáº·c t-SNE).  

                                - **MÃ u sáº¯c** ğŸ¨:  
                                - Má»—i mÃ u tÆ°á»£ng trÆ°ng cho má»™t cá»¥m dá»¯ liá»‡u khÃ¡c nhau.  
                                - VÃ¬ cÃ³ quÃ¡ nhiá»u mÃ u khÃ¡c nhau, Ä‘iá»u nÃ y cho tháº¥y thuáº­t toÃ¡n Ä‘Ã£ chia dá»¯ liá»‡u thÃ nh quÃ¡ nhiá»u cá»¥m.  

                                - **Trá»¥c X vÃ  Y** ğŸ“‰:  
                                - Trá»¥c X vÃ  Y dao Ä‘á»™ng tá»« -10 Ä‘áº¿n khoáº£ng 30, pháº£n Ã¡nh sá»± phÃ¢n bá»‘ dá»¯ liá»‡u.  
                                - Äiá»u nÃ y gá»£i Ã½ ráº±ng dá»¯ liá»‡u gá»‘c cÃ³ thá»ƒ Ä‘Ã£ Ä‘Æ°á»£c giáº£m chiá»u trÆ°á»›c khi phÃ¢n cá»¥m.  

                                - **ChÃº thÃ­ch (legend)** ğŸ·ï¸:  
                                - CÃ¡c nhÃ£n cá»¥m cho tháº¥y thuáº­t toÃ¡n DBSCAN Ä‘Ã£ tÃ¬m tháº¥y ráº¥t nhiá»u cá»¥m khÃ¡c nhau.  
                                - Äiá»u nÃ y cÃ³ thá»ƒ lÃ  do tham sá»‘ `eps` quÃ¡ nhá», khiáº¿n thuáº­t toÃ¡n coi nhiá»u Ä‘iá»ƒm dá»¯ liá»‡u riÃªng láº» lÃ  má»™t cá»¥m riÃªng biá»‡t.  
                                """)
                        mlflow.end_run()
            else:
                st.error("ğŸš¨ Dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c xá»­ lÃ½! HÃ£y Ä‘áº£m báº£o báº¡n Ä‘Ã£ cháº¡y pháº§n tiá»n xá»­ lÃ½ dá»¯ liá»‡u trÆ°á»›c khi thá»±c hiá»‡n phÃ¢n cá»¥m.")
            

    with tab_split:
        with st.expander(" ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh phÃ¢n cá»¥m", expanded=True):
            if "clustering_method" not in st.session_state:
                st.session_state.clustering_method = "K-means"  # GiÃ¡ trá»‹ máº·c Ä‘á»‹nh
                clustering_method = st.session_state.clustering_method  # Láº¥y giÃ¡ trá»‹ tá»« session_state
            if clustering_method == "K-means" and 'labels' in locals():
                silhouette_avg = silhouette_score(X_train_pca, labels)
                dbi_score = davies_bouldin_score(X_train_pca, labels)

                st.markdown("### ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh K-means")
                st.write(f"âœ… **Silhouette Score**: {silhouette_avg:.4f}")
                st.write(f"âœ… **Davies-Bouldin Index**: {dbi_score:.4f}")

                # Váº½ biá»ƒu Ä‘á»“ Silhouette Score
                fig, ax = plt.subplots(figsize=(6, 4))
                sample_silhouette_values = silhouette_samples(X_train_pca, labels)
                y_lower = 10

                for i in range(k):
                    ith_cluster_silhouette_values = sample_silhouette_values[labels == i]
                    ith_cluster_silhouette_values.sort()
                    size_cluster_i = ith_cluster_silhouette_values.shape[0]
                    y_upper = y_lower + size_cluster_i

                ax.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, alpha=0.7)
                ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
                y_lower = y_upper + 10

                ax.set_title("Biá»ƒu Ä‘á»“ Silhouette Score - K-means")
                ax.set_xlabel("Silhouette Score")
                ax.set_ylabel("Cá»¥m")
                ax.axvline(x=silhouette_avg, color="red", linestyle="--", label="GiÃ¡ trá»‹ trung bÃ¬nh")
                ax.legend()

                st.pyplot(fig)

                    # Giáº£i thÃ­ch vá» biá»ƒu Ä‘á»“
                st.markdown("**Giáº£i thÃ­ch biá»ƒu Ä‘á»“ Silhouette Score**")
                st.write("""
                - **Trá»¥c hoÃ nh**: Silhouette Score (tá»« -1 Ä‘áº¿n 1).
                - **Trá»¥c tung**: CÃ¡c cá»¥m Ä‘Æ°á»£c phÃ¡t hiá»‡n.
                - **Dáº£i mÃ u**: Äá»™ rá»™ng biá»ƒu thá»‹ sá»‘ lÆ°á»£ng Ä‘iá»ƒm trong tá»«ng cá»¥m.
                - **ÄÆ°á»ng Ä‘á»©t Ä‘á»**: Trung bÃ¬nh Silhouette Score cá»§a toÃ n bá»™ dá»¯ liá»‡u.
                - **Silhouette Score Ã¢m**: CÃ³ thá»ƒ má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n cá»¥m sai.
                """)

            elif clustering_method == "DBSCAN" and 'labels' in locals():
                unique_labels = set(labels)
                if len(unique_labels) > 1:  # TrÃ¡nh lá»—i khi chá»‰ cÃ³ 1 cá»¥m hoáº·c toÃ n bá»™ Ä‘iá»ƒm bá»‹ coi lÃ  nhiá»…u (-1)
                    silhouette_avg = silhouette_score(X_train_pca, labels)
                    dbi_score = davies_bouldin_score(X_train_pca, labels)

                    st.markdown("### ğŸ“Š ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh DBSCAN")
                    st.write(f"âœ… **Silhouette Score**: {silhouette_avg:.4f}")
                    st.write(f"âœ… **Davies-Bouldin Index**: {dbi_score:.4f}")

                    # Váº½ biá»ƒu Ä‘á»“ Silhouette Score
                    fig, ax = plt.subplots(figsize=(6, 4))
                    sample_silhouette_values = silhouette_samples(X_train_pca, labels)
                    y_lower = 10

                    for i in unique_labels:
                        if i == -1:  # Bá» qua nhiá»…u
                            continue
                        ith_cluster_silhouette_values = sample_silhouette_values[labels == i]
                        ith_cluster_silhouette_values.sort()
                        size_cluster_i = ith_cluster_silhouette_values.shape[0]
                        y_upper = y_lower + size_cluster_i

                        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values, alpha=0.7)
                        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))
                        y_lower = y_upper + 10

                    ax.set_title("Biá»ƒu Ä‘á»“ Silhouette Score - DBSCAN")
                    ax.set_xlabel("Silhouette Score")
                    ax.set_ylabel("Cá»¥m")
                    ax.axvline(x=silhouette_avg, color="red", linestyle="--", label="GiÃ¡ trá»‹ trung bÃ¬nh")
                    ax.legend()

                    st.pyplot(fig)

                    # Giáº£i thÃ­ch chi tiáº¿t vá» biá»ƒu Ä‘á»“ Silhouette Score - DBSCAN
                    st.markdown("**Giáº£i thÃ­ch biá»ƒu Ä‘á»“ Silhouette Score (DBSCAN)**")
                    st.write("""
                    - **Trá»¥c tung (Cá»¥m - Cluster ID)**: Má»—i cá»¥m Ä‘Æ°á»£c hiá»ƒn thá»‹ vá»›i má»™t dáº£i mÃ u.
                    - **Trá»¥c hoÃ nh (Silhouette Score)**: GiÃ¡ trá»‹ cÃ ng gáº§n **1** thÃ¬ phÃ¢n cá»¥m cÃ ng tá»‘t, gáº§n **0** lÃ  chá»“ng chÃ©o, Ã¢m lÃ  phÃ¢n cá»¥m kÃ©m.
                    - **ÄÆ°á»ng Ä‘á» nÃ©t Ä‘á»©t**: Silhouette Score trung bÃ¬nh cá»§a toÃ n bá»™ cá»¥m.
                    """)

                    st.markdown("ğŸ” **Vá» cÃ¡c Ä‘Æ°á»ng Ä‘en trong biá»ƒu Ä‘á»“**")

                    st.write("""
                    - ÄÃ¢y lÃ  cÃ¡c Ä‘iá»ƒm nhiá»…u (outliers) mÃ  DBSCAN khÃ´ng thá»ƒ gÃ¡n vÃ o cá»¥m nÃ o.
                    - Trong DBSCAN, cÃ¡c Ä‘iá»ƒm nhiá»…u Ä‘Æ°á»£c gÃ¡n nhÃ£n `-1`, nhÆ°ng khÃ´ng Ä‘Æ°á»£c hiá»ƒn thá»‹ trÃªn biá»ƒu Ä‘á»“.
                    - Tuy nhiÃªn, má»™t sá»‘ Ä‘iá»ƒm nhiá»…u cÃ³ thá»ƒ váº«n xuáº¥t hiá»‡n nhÆ° **cÃ¡c vá»‡t Ä‘en dá»c**, do chÃºng cÃ³ Silhouette Score gáº§n giá»‘ng nhau nhÆ°ng khÃ´ng thuá»™c báº¥t ká»³ cá»¥m nÃ o.

                    **Äiá»u nÃ y xáº£y ra khi:**
                    - Sá»‘ lÆ°á»£ng Ä‘iá»ƒm nhiá»…u lá»›n.
                    - Silhouette Score cá»§a nhiá»…u khÃ´ng á»•n Ä‘á»‹nh, khiáº¿n nhiá»u Ä‘iá»ƒm cÃ³ giÃ¡ trá»‹ gáº§n nhau.
                    - Cá»¥m cÃ³ cháº¥t lÆ°á»£ng kÃ©m, tá»©c lÃ  thuáº­t toÃ¡n Ä‘ang nháº­n diá»‡n ráº¥t nhiá»u Ä‘iá»ƒm lÃ  nhiá»…u thay vÃ¬ cá»¥m rÃµ rÃ ng.
                    """)
                else:
                    st.warning("âš ï¸ DBSCAN chá»‰ tÃ¬m tháº¥y 1 cá»¥m hoáº·c táº¥t cáº£ Ä‘iá»ƒm bá»‹ coi lÃ  nhiá»…u. HÃ£y thá»­ Ä‘iá»u chá»‰nh `eps` vÃ  `min_samples`.")

    with tab_mlflow:
        st.header("ThÃ´ng tin Huáº¥n luyá»‡n & MLflow UI")
        try:
            client = MlflowClient()
            experiment_name = "MyExperiment"
    
            # Kiá»ƒm tra náº¿u experiment Ä‘Ã£ tá»“n táº¡i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment má»›i Ä‘Æ°á»£c táº¡o vá»›i ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"Äang sá»­ dá»¥ng experiment ID: {experiment_id}")
    
            mlflow.set_experiment(experiment_name)
    
            # Truy váº¥n cÃ¡c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])
    
            # 1) Chá»n vÃ  Ä‘á»•i tÃªn Run Name
            st.subheader("Äá»•i tÃªn Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                               for run in runs}
                selected_run_id_for_rename = st.selectbox("Chá»n Run Ä‘á»ƒ Ä‘á»•i tÃªn:", 
                                                          options=list(run_options.keys()), 
                                                          format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nháº­p tÃªn má»›i cho Run:", 
                                             value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("Cáº­p nháº­t tÃªn Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ÄÃ£ cáº­p nháº­t tÃªn Run thÃ nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui lÃ²ng nháº­p tÃªn má»›i cho Run.")
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log.")
    
            # 2) XÃ³a Run
            st.subheader("Danh sÃ¡ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                         options=list(run_options.keys()), 
                                                         format_func=lambda x: run_options[x])
                if st.button("XÃ³a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ÄÃ£ xÃ³a Run {run_options[selected_run_id_to_delete]} thÃ nh cÃ´ng!")
                    st.experimental_rerun()  # Tá»± Ä‘á»™ng lÃ m má»›i giao diá»‡n
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘á»ƒ xÃ³a.")
    
            # 3) Danh sÃ¡ch cÃ¡c thÃ­ nghiá»‡m
            st.subheader("Danh sÃ¡ch cÃ¡c Run Ä‘Ã£ log")
            if runs:
                selected_run_id = st.selectbox("Chá»n Run Ä‘á»ƒ xem chi tiáº¿t:", 
                                               options=list(run_options.keys()), 
                                               format_func=lambda x: run_options[x])
    
                # 4) Hiá»ƒn thá»‹ thÃ´ng tin chi tiáº¿t cá»§a Run Ä‘Æ°á»£c chá»n
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
    
                st.markdown("### Tham sá»‘ Ä‘Ã£ log")
                st.json(selected_run.data.params)
    
                st.markdown("### Chá»‰ sá»‘ Ä‘Ã£ log")
                metrics = {
                    "Mean CV Score (RÂ²)": selected_run.data.metrics.get("mean_cv_score", "N/A"),
                    "Validation MSE": selected_run.data.metrics.get("validation_mse", "N/A"),
                    "Validation RÂ²": selected_run.data.metrics.get("validation_r2", "N/A"),
                    "Validation Accuracy": selected_run.data.metrics.get("validation_accuracy", "N/A"),
                    "Test MSE": selected_run.data.metrics.get("test_mse", "N/A"),
                    "Test RÂ²": selected_run.data.metrics.get("test_r2", "N/A"),
                    "Test Accuracy": selected_run.data.metrics.get("test_accuracy", "N/A")
                }
                st.json(metrics)
    
                # 5) NÃºt báº¥m má»Ÿ MLflow UI
                st.subheader("Truy cáº­p MLflow UI")
                mlflow_url = "https://dagshub.com/Dung2204/HMVPython.mlflow"
                if st.button("Má»Ÿ MLflow UI"):
                    st.markdown(f'**[Click Ä‘á»ƒ má»Ÿ MLflow UI]({mlflow_url})**')
            else:
                st.info("ChÆ°a cÃ³ Run nÃ o Ä‘Æ°á»£c log. Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
    
        except Exception as e:
            st.error(f"KhÃ´ng thá»ƒ káº¿t ná»‘i vá»›i MLflow: {e}")    

if __name__ == "__main__":
    run_ClusteringMinst_app()    


# st.write(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
# with st.expander("ğŸ–¼ï¸ ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh phÃ¢n cá»¥m", expanded=True):
#     # st.write(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
#     print("ğŸ¯ Kiá»ƒm tra trÃªn DagsHub: https://dagshub.com/Dung2204/Minst-mlflow.mlflow")


# # # # cd "C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\BaiThucHanh4"
