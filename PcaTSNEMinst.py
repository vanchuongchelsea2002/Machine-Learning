
import streamlit as st
import os
import cv2
import numpy as np
import pandas as pd
import pickle
import seaborn as sns
import random
import struct
import altair
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
import mlflow
from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import pairwise_distances
from sklearn.svm import SVC
from sklearn.manifold import TSNE
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from PIL import Image
from collections import Counter
from mlflow.tracking import MlflowClient

def run_PcaTSNEMinst_app():
    @st.cache_data  # L∆∞u cache ƒë·ªÉ tr√°nh load l·∫°i d·ªØ li·ªáu m·ªói l·∫ßn ch·∫°y l·∫°i Streamlit
    def get_sampled_pixels(images, sample_size=100_000):
        return np.random.choice(images.flatten(), sample_size, replace=False)

    @st.cache_data  # Cache danh s√°ch ·∫£nh ng·∫´u nhi√™n
    def get_random_indices(num_images, total_images):
        return np.random.randint(0, total_images, size=num_images)

    # C·∫•u h√¨nh Streamlit
    #   st.set_page_config(page_title="Ph√¢n lo·∫°i ·∫£nh", layout="wide")
    # ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ ƒë·ªçc file .idx
    def load_mnist_images(filename):
        with open(filename, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
        return images

    def load_mnist_labels(filename):
        with open(filename, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            labels = np.fromfile(f, dtype=np.uint8)
        return labels

    mlflow_tracking_uri = st.secrets["MLFLOW_TRACKING_URI"]
    mlflow_username = st.secrets["MLFLOW_TRACKING_USERNAME"]
    mlflow_password = st.secrets["MLFLOW_TRACKING_PASSWORD"]
    
    # Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng
    os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
    os.environ["MLFLOW_TRACKING_USERNAME"] = mlflow_username
    os.environ["MLFLOW_TRACKING_PASSWORD"] = mlflow_password
    
    # Thi·∫øt l·∫≠p MLflow (ƒê·∫∑t sau khi mlflow_tracking_uri ƒë√£ c√≥ gi√° tr·ªã)
    mlflow.set_tracking_uri(mlflow_tracking_uri)



    # ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n ƒë·∫øn c√°c file MNIST
    # dataset_path = r"C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App"
    dataset_path = os.path.dirname(os.path.abspath(__file__)) 
    train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
    train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
    test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
    test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

    if "train_images" not in st.session_state:
            st.session_state.train_images = load_mnist_images(train_images_path)
            st.session_state.train_labels = load_mnist_labels(train_labels_path)
            st.session_state.test_images = load_mnist_images(test_images_path)
            st.session_state.test_labels = load_mnist_labels(test_labels_path)
    # T·∫£i d·ªØ li·ªáu
    train_images = load_mnist_images(train_images_path)
    train_labels = load_mnist_labels(train_labels_path)
    test_images = load_mnist_images(test_images_path)
    test_labels = load_mnist_labels(test_labels_path)

    

    # Giao di·ªán Streamlit
    st.title("üì∏ MNIST PCA_T-SNE")
    tabs = st.tabs([
            "T·∫≠p d·ªØ li·ªáu",
            "X·ª≠ l√≠ d·ªØ li·ªáu",
            "Th√¥ng tin",
            "k·ªπ thu·∫≠t thu g·ªçn chi·ªÅu",
            "ƒê√°nh gi√° m√¥ h√¨nh",
            "Th√¥ng tin & Mlflow",
    ])
    tab_info, tab_load,tab_note, tab_preprocess, tab_split ,tab_mlflow= tabs
    with tab_info:
        with st.expander("**Th√¥ng tin d·ªØ li·ªáu**", expanded=True):
            st.markdown(
                '''
                **MNIST** l√† phi√™n b·∫£n ƒë∆∞·ª£c ch·ªânh s·ª≠a t·ª´ b·ªô d·ªØ li·ªáu **NIST g·ªëc** c·ªßa Vi·ªán Ti√™u chu·∫©n v√† C√¥ng ngh·ªá Qu·ªëc gia Hoa K·ª≥.  
                B·ªô d·ªØ li·ªáu ban ƒë·∫ßu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay t·ª´ **nh√¢n vi√™n b∆∞u ƒëi·ªán** v√† **h·ªçc sinh trung h·ªçc**.  

                C√°c nh√† nghi√™n c·ª©u **Yann LeCun, Corinna Cortes, v√† Christopher Burges** ƒë√£ x·ª≠ l√Ω, chu·∫©n h√≥a v√† chuy·ªÉn ƒë·ªïi b·ªô d·ªØ li·ªáu n√†y th√†nh **MNIST**  
                ƒë·ªÉ d·ªÖ d√†ng s·ª≠ d·ª•ng h∆°n cho c√°c b√†i to√°n nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay.
                '''
            )
            # ƒê·∫∑c ƒëi·ªÉm c·ªßa b·ªô d·ªØ li·ªáu
        with st.expander("**ƒê·∫∑c ƒëi·ªÉm c·ªßa b·ªô d·ªØ li·ªáu**", expanded=True):
            st.markdown(
                '''
                - **S·ªë l∆∞·ª£ng ·∫£nh:** 70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay  
                - **K√≠ch th∆∞·ªõc ·∫£nh:** M·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc 28x28 pixel  
                - **C∆∞·ªùng ƒë·ªô ƒëi·ªÉm ·∫£nh:** T·ª´ 0 (m√†u ƒëen) ƒë·∫øn 255 (m√†u tr·∫Øng)  
                - **D·ªØ li·ªáu nh√£n:** M·ªói ·∫£nh ƒëi k√®m v·ªõi m·ªôt nh√£n s·ªë t·ª´ 0 ƒë·∫øn 9  
                '''
            )
            st.write(f"üîç S·ªë l∆∞·ª£ng ·∫£nh hu·∫•n luy·ªán: `{train_images.shape[0]}`")
            st.write(f"üîç S·ªë l∆∞·ª£ng ·∫£nh ki·ªÉm tra: `{test_images.shape[0]}`")


        with st.expander("**Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u c·ªßa t·ª´ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9 trong t·∫≠p hu·∫•n luy·ªán**", expanded=True):
            label_counts = pd.Series(train_labels).value_counts().sort_index()
            # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu d∆∞·ªõi bi·ªÉu ƒë·ªì
            df_counts = pd.DataFrame({"Ch·ªØ s·ªë": label_counts.index, "S·ªë l∆∞·ª£ng m·∫´u": label_counts.values})
            st.dataframe(df_counts)
            num_images = 10
            random_indices = random.sample(range(len(train_images)), num_images)
            fig, axes = plt.subplots(1, num_images, figsize=(15, 5))
            st.write("**M·ªôt s·ªë ·∫£nh v√≠ d·ª•:**")
            for ax, idx in zip(axes, random_indices):
                ax.imshow(train_images[idx], cmap='gray')
                ax.axis("off")
                ax.set_title(f"Label: {train_labels[idx]}")

            st.pyplot(fig)

        with st.expander("**Ki·ªÉm tra h√¨nh d·∫°ng c·ªßa t·∫≠p d·ªØ li·ªáu**", expanded=True):    
                # Ki·ªÉm tra h√¨nh d·∫°ng c·ªßa t·∫≠p d·ªØ li·ªáu
            st.write("üîç H√¨nh d·∫°ng t·∫≠p hu·∫•n luy·ªán:", train_images.shape)
            st.write("üîç H√¨nh d·∫°ng t·∫≠p ki·ªÉm tra:", test_images.shape)
            # Ki·ªÉm tra xem c√≥ gi√° tr·ªã pixel n√†o ngo√†i ph·∫°m vi 0-255 kh√¥ng
            if (train_images.min() < 0) or (train_images.max() > 255):
                st.error("‚ö†Ô∏è C·∫£nh b√°o: C√≥ gi√° tr·ªã pixel ngo√†i ph·∫°m vi 0-255!")
            else:
                st.success("‚úÖ D·ªØ li·ªáu pixel h·ª£p l·ªá (0 - 255).")

            # Chu·∫©n h√≥a d·ªØ li·ªáu
            train_images = train_images.astype("float32") / 255.0
            test_images = test_images.astype("float32") / 255.0

            # Hi·ªÉn th·ªã th√¥ng b√°o sau khi chu·∫©n h√≥a
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ kho·∫£ng [0,1].")

            # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a (d·∫°ng s·ªë)
            num_samples = 5  # S·ªë l∆∞·ª£ng m·∫´u hi·ªÉn th·ªã
            df_normalized = pd.DataFrame(train_images[:num_samples].reshape(num_samples, -1))  

            # st.write("**B·∫£ng d·ªØ li·ªáu sau khi chu·∫©n h√≥a**")
            # st.dataframe(df_normalized)

            
            sample_size = 10_000  
            pixel_sample = np.random.choice(train_images.flatten(), sample_size, replace=False)



    with tab_load:
        with st.expander("**X·ª≠ l√Ω d·ªØ li·ªáu**", expanded=True):    
            # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh vector 1 chi·ªÅu
            X_train = st.session_state.train_images.reshape(st.session_state.train_images.shape[0], -1)
            X_test = st.session_state.test_images.reshape(st.session_state.test_images.shape[0], -1)
            y_train = train_labels
            y_test = test_labels

            # Ch·ªçn t·ª∑ l·ªá t·∫≠p validation
            val_size = st.slider("üîπ **Ch·ªçn t·ª∑ l·ªá t·∫≠p validation (%)**", min_value=10, max_value=50, value=20, step=5) / 100

            # Ch·ªçn t·ª∑ l·ªá t·∫≠p ki·ªÉm tra (test)
            test_size = st.slider("üîπ **Ch·ªçn t·ª∑ l·ªá t·∫≠p ki·ªÉm tra (%)**", min_value=10, max_value=40, value=20, step=5) / 100

            # Chia t·∫≠p train ban ƒë·∫ßu th√†nh train + validation + test
            X_train, X_temp, y_train, y_temp = train_test_split(X_train, y_train, test_size=(val_size + test_size), random_state=42)

            # Ti·∫øp t·ª•c chia X_temp th√†nh validation v√† test theo t·ª∑ l·ªá ƒë√£ ch·ªçn
            X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=(test_size / (val_size + test_size)), random_state=42)

            st.session_state.X_train = X_train
            st.session_state.X_val = X_val
            st.session_state.X_test = X_test


            st.write("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† chia t√°ch.")
            st.write(f"üîπ **K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán**: `{X_train.shape}`")
            st.write(f"üîπ **K√≠ch th∆∞·ªõc t·∫≠p validation**: `{X_val.shape}`")
            st.write(f"üîπ **K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra**: `{X_test.shape}`")

            # Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi nh√£n trong t·∫≠p hu·∫•n luy·ªán
            fig, ax = plt.subplots(figsize=(6, 4))
            sns.barplot(x=list(Counter(y_train).keys()), y=list(Counter(y_train).values()), palette="Blues", ax=ax)
            ax.set_title("Ph√¢n ph·ªëi nh√£n trong t·∫≠p hu·∫•n luy·ªán")
            ax.set_xlabel("Nh√£n")
            ax.set_ylabel("S·ªë l∆∞·ª£ng")
            st.pyplot(fig)

    with tab_note:
        with st.expander("**Th√¥ng tin m√¥ h√¨nh**", expanded=True):
            # Ch·ªçn m√¥ h√¨nh*
            model_option1 = st.selectbox("Ch·ªçn m√¥ h√¨nh", ["PCA (Principal Component Analysis)", "T-SNE (t-Distributed Stochastic Neighbor Embedding)"])
            
            if model_option1 == "PCA (Principal Component Analysis)":
                st.markdown("## üîπ PCA (Principal Component Analysis)")
                st.markdown("---")
                st.markdown("### PCA - Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh")
                st.write(
                    "**PCA (Principal Component Analysis)** l√† m·ªôt k·ªπ thu·∫≠t gi·∫£m chi·ªÅu d·ªØ li·ªáu tuy·∫øn t√≠nh, gi√∫p chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu c√≥ nhi·ªÅu chi·ªÅu "
                    "th√†nh m·ªôt t·∫≠p h·ª£p nh·ªè h∆°n c√°c th√†nh ph·∫ßn ch√≠nh c√≥ th·ªÉ gi·ªØ l·∫°i nhi·ªÅu nh·∫•t th√¥ng tin g·ªëc. "
                    "PCA ho·∫°t ƒë·ªông b·∫±ng c√°ch t√¨m c√°c h∆∞·ªõng c√≥ ph∆∞∆°ng sai l·ªõn nh·∫•t c·ªßa d·ªØ li·ªáu, sau ƒë√≥ chi·∫øu d·ªØ li·ªáu l√™n c√°c h∆∞·ªõng ƒë√≥."
                )
                st.markdown("### Tham s·ªë quan tr·ªçng c·ªßa PCA")
                st.write("**Tham s·ªë `n_components`:**")
                st.write("- X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng th√†nh ph·∫ßn ch√≠nh c·∫ßn gi·ªØ l·∫°i.")
                st.write("- N·∫øu `n_components=k`, PCA gi·ªØ l·∫°i **k th√†nh ph·∫ßn ch√≠nh**.")
                st.write("- N·∫øu `n_components=None`, gi·ªØ l·∫°i to√†n b·ªô d·ªØ li·ªáu.")
                st.write("- C√≥ th·ªÉ ch·ªçn `n_components=0.95` ƒë·ªÉ gi·ªØ l·∫°i 95% ph∆∞∆°ng sai.")
                st.markdown("**Tham s·ªë `svd_solver`:**")
                st.write("- X√°c ƒë·ªãnh thu·∫≠t to√°n SVD ƒë·ªÉ t√≠nh PCA.")
                st.write("- C√°c gi√° tr·ªã: `'auto'`, `'full'`, `'arpack'`, `'randomized'`.")
                st.write("- Th∆∞·ªùng d√πng `'randomized'` khi d·ªØ li·ªáu l·ªõn ƒë·ªÉ tƒÉng t·ªëc.")
                st.markdown("**Tham s·ªë `whiten`:**")
                st.write("- N·∫øu `whiten=True`, PCA chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ ph∆∞∆°ng sai m·ªói th√†nh ph·∫ßn ch√≠nh = 1.")
                st.write("- H·ªØu √≠ch khi c·∫ßn d·ªØ li·ªáu c√≥ d·∫°ng chu·∫©n t·∫Øc h∆°n.")

                st.markdown("### C√°c b∆∞·ªõc thu g·ªçn chi·ªÅu v·ªõi PCA")
                st.write("1. **Chu·∫©n h√≥a d·ªØ li·ªáu**: ƒê∆∞a d·ªØ li·ªáu v·ªÅ c√πng m·ªôt thang ƒëo (`mean` = 0, `variance` = 1).")
                st.write("2. **T√≠nh ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai**: ƒê√°nh gi√° s·ª± t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn.")
                st.write("3. **T√≠nh gi√° tr·ªã ri√™ng v√† vector ri√™ng**: T√¨m c√°c th√†nh ph·∫ßn ch√≠nh d·ª±a tr√™n c√°c vector ri√™ng.")
                st.write("4. **Ch·ªçn s·ªë l∆∞·ª£ng th√†nh ph·∫ßn ch√≠nh**: Gi·ªØ l·∫°i c√°c th√†nh ph·∫ßn ch√≠nh c√≥ gi√° tr·ªã ri√™ng l·ªõn nh·∫•t.")
                st.write("5. **Chi·∫øu d·ªØ li·ªáu v√†o kh√¥ng gian m·ªõi**: Bi·ªÉu di·ªÖn d·ªØ li·ªáu trong h·ªá tr·ª•c m·ªõi c√≥ √≠t chi·ªÅu h∆°n.")
                
                st.markdown("### ∆Øu ƒëi·ªÉm & Nh∆∞·ª£c ƒëi·ªÉm c·ªßa PCA")
                st.table({
                    "**∆Øu ƒëi·ªÉm**": [
                        "Gi·∫£m chi·ªÅu nhanh, hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu tuy·∫øn t√≠nh.",
                        "D·ªÖ tri·ªÉn khai, gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng."
                    ],
                    "**Nh∆∞·ª£c ƒëi·ªÉm**": [
                        "Kh√¥ng ho·∫°t ƒë·ªông t·ªët v·ªõi d·ªØ li·ªáu phi tuy·∫øn t√≠nh.",
                        "M·∫•t m·ªôt ph·∫ßn th√¥ng tin do n√©n d·ªØ li·ªáu."
                    ]
                })
                
            elif model_option1 == "T-SNE (t-Distributed Stochastic Neighbor Embedding)":
                st.markdown("## üîπ T-SNE (t-Distributed Stochastic Neighbor Embedding) ")
                st.markdown("---")
                st.markdown("### T-SNE- Ph√¢n t√≠ch th√†nh ph·∫ßn ch√≠nh")
                st.write(
                    "**T-SNE (t-Distributed Stochastic Neighbor Embedding)** l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu d·ªØ li·ªáu phi tuy·∫øn t√≠nh, chuy√™n d√πng ƒë·ªÉ tr·ª±c quan h√≥a d·ªØ li·ªáu c√≥ chi·ªÅu cao. "
                    "N√≥ ho·∫°t ƒë·ªông b·∫±ng c√°ch gi·ªØ l·∫°i m·ªëi quan h·ªá c·ª•c b·ªô gi·ªØa c√°c ƒëi·ªÉm d·ªØ li·ªáu v√† √°nh x·∫° ch√∫ng v√†o kh√¥ng gian c√≥ chi·ªÅu th·∫•p h∆°n.")
                
                st.markdown("### Tham s·ªë quan tr·ªçng c·ªßa T-SNE")

                st.markdown("**Tham s·ªë `n_components`:**")
                st.write("- X√°c ƒë·ªãnh s·ªë chi·ªÅu ƒë·∫ßu ra (th∆∞·ªùng l√† **2 ho·∫∑c 3** ƒë·ªÉ tr·ª±c quan h√≥a).")

                st.markdown("**Tham s·ªë `perplexity`:**")
                st.write("- ƒêi·ªÅu ch·ªânh s·ªë l∆∞·ª£ng h√†ng x√≥m quan tr·ªçng c·ªßa m·ªói ƒëi·ªÉm.")
                st.write("- Gi√° tr·ªã h·ª£p l√Ω: **5 ƒë·∫øn 50** (c·∫ßn th·ª≠ nghi·ªám ƒë·ªÉ t·ªëi ∆∞u).")

                st.markdown("**Tham s·ªë `learning_rate`:**")
                st.write("- Ki·ªÉm so√°t t·ªëc ƒë·ªô c·∫≠p nh·∫≠t v·ªã tr√≠ ƒëi·ªÉm d·ªØ li·ªáu.")
                st.write("- Gi√° tr·ªã th∆∞·ªùng d√πng: **10 - 1000** (m·∫∑c ƒë·ªãnh l√† `200`).")

                st.markdown("**Tham s·ªë `n_iter`:**")
                st.write("- S·ªë v√≤ng l·∫∑p t·ªëi ∆∞u h√≥a thu·∫≠t to√°n.")
                st.write("- Gi√° tr·ªã th∆∞·ªùng d√πng: **1000 - 5000**.")

                st.markdown("**Tham s·ªë `metric`:**")
                st.write("- X√°c ƒë·ªãnh kho·∫£ng c√°ch ƒë·ªÉ t√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng gi·ªØa ƒëi·ªÉm d·ªØ li·ªáu.")
                st.write("- M·∫∑c ƒë·ªãnh l√† `'euclidean'`, c√≥ th·ªÉ d√πng `'cosine'`, `'manhattan'`, v.v.")

                st.markdown("###  C√°c b∆∞·ªõc thu g·ªçn chi·ªÅu v·ªõi T-SNE")
                st.write("1. **T√≠nh to√°n ph√¢n b·ªë kho·∫£ng c√°ch**: S·ª≠ d·ª•ng ph√¢n ph·ªëi Gaussian ·ªü kh√¥ng gian cao chi·ªÅu.")
                st.write("2. **T√≠nh to√°n ph√¢n b·ªë trong kh√¥ng gian th·∫•p**: S·ª≠ d·ª•ng ph√¢n ph·ªëi t-Student ƒë·ªÉ duy tr√¨ quan h·ªá t∆∞∆°ng ƒë·ªìng.")
                st.write("3. **Gi·∫£m thi·ªÉu h√†m m·∫•t m√°t**: ƒêi·ªÅu ch·ªânh v·ªã tr√≠ ƒëi·ªÉm d·ªØ li·ªáu ƒë·ªÉ t·ªëi ∆∞u s·ª± t∆∞∆°ng ƒë·ªìng.")
                st.write("4. **Tr·ª±c quan h√≥a d·ªØ li·ªáu**: Hi·ªÉn th·ªã d·ªØ li·ªáu trong kh√¥ng gian 2D ho·∫∑c 3D.")
                
                st.markdown("###  ∆Øu ƒëi·ªÉm & Nh∆∞·ª£c ƒëi·ªÉm c·ªßa T-SNE")
                st.table({
                    "**∆Øu ƒëi·ªÉm**": [
                        "Gi·ªØ l·∫°i t·ªët m·ªëi quan h·ªá c·ª•c b·ªô gi·ªØa c√°c ƒëi·ªÉm.",
                        "Hi·ªáu qu·∫£ khi tr·ª±c quan h√≥a d·ªØ li·ªáu nhi·ªÅu chi·ªÅu."
                    ],
                    "**Nh∆∞·ª£c ƒëi·ªÉm**": [
                        "Ch·∫≠m h∆°n PCA, kh√¥ng ph√π h·ª£p cho d·ªØ li·ªáu l·ªõn.",
                        "Kh√¥ng th·ªÉ d√πng ƒë·ªÉ bi·∫øn ƒë·ªïi d·ªØ li·ªáu m·ªõi."
                    ]
                })



    with tab_preprocess:
        with st.expander("**k·ªπ thu·∫≠t thu g·ªçn chi·ªÅu**", expanded=True):    

            if "X_train" in st.session_state and "X_val" in st.session_state and "X_test" in st.session_state:
                # L·∫•y d·ªØ li·ªáu t·ª´ session_state
                X_train = st.session_state.X_train
                X_val = st.session_state.X_val
                X_test = st.session_state.X_test
                # Chu·∫©n h√≥a d·ªØ li·ªáu
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_val_scaled = scaler.transform(X_val)
                X_test_scaled = scaler.transform(X_test)

                st.session_state.X_train_scaled = X_train_scaled
                st.session_state.X_val_scaled = X_val_scaled
                st.session_state.X_test_scaled = X_test_scaled

                    
                    # Ch·ªçn ph∆∞∆°ng ph√°p ph√¢n c·ª•m
                dim_reduction_method = st.selectbox("**Ch·ªçn ph∆∞∆°ng ph√°p thu g·ªçn chi·ªÅu:**", ["PCA", "t-SNE"])
                if dim_reduction_method == "PCA":
                    # Tham s·ªë c·ªßa PCA
                    n_components = st.slider("**S·ªë th√†nh ph·∫ßn ch√≠nh (n_components):**", min_value=2, max_value=min(X_train.shape[1], 20), value=5)
                    svd_solver = st.selectbox("**Thu·∫≠t to√°n SVD:**", ["auto", "full", "arpack", "randomized"])
                    whiten = st.checkbox("**Chu·∫©n h√≥a d·ªØ li·ªáu (whiten):**", value=False)

                    if st.button("üöÄ Ch·∫°y PCA"):
                        with mlflow.start_run():
                            # √Åp d·ª•ng PCA
                            pca = PCA(n_components=n_components, svd_solver=svd_solver, whiten=whiten, random_state=42)
                            X_train_pca = pca.fit_transform(X_train_scaled)

                            # Log tham s·ªë v√†o MLflow
                            mlflow.log_param("algorithm", "PCA")
                            mlflow.log_param("n_components", n_components)
                            mlflow.log_param("svd_solver", svd_solver)
                            mlflow.log_param("whiten", whiten)
                            st.session_state.X_train_pca = X_train_pca
                            st.session_state.explained_variance_ratio_ = pca.explained_variance_ratio_
                            mlflow.log_param("X_train_pca",X_train_pca)
                            # Log ph∆∞∆°ng sai gi·∫£i th√≠ch
                            explained_variance = np.sum(pca.explained_variance_ratio_)
                            mlflow.log_metric("explained_variance", explained_variance)

                            # V·∫Ω bi·ªÉu ƒë·ªì
                            fig, ax = plt.subplots(figsize=(6, 4))
                            scatter = ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], alpha=0.5, cmap="coolwarm")
                            ax.set_title(f"PCA v·ªõi {n_components} th√†nh ph·∫ßn ch√≠nh")
                            st.pyplot(fig)

                            fig.savefig("pca_result.png")
                            mlflow.log_artifact("pca_result.png")

                            st.markdown(
                                f"""
                                ### K·∫øt qu·∫£ PCA:
                                - T·ªïng ph∆∞∆°ng sai ƒë∆∞·ª£c gi·ªØ l·∫°i: {explained_variance:.2f}  
                                - **PCA** gi√∫p gi·∫£m chi·ªÅu d·ªØ li·ªáu trong khi v·∫´n gi·ªØ l·∫°i th√¥ng tin quan tr·ªçng. 
                                """
                            )
                        mlflow.end_run()

                elif dim_reduction_method == "t-SNE":
                    # Tham s·ªë c·ªßa t-SNE
                    n_components = st.selectbox("**S·ªë chi·ªÅu ƒë·∫ßu ra:**", [2, 3])
                    if st.toggle("Hi·ªÉn th·ªã th√¥ng tin s·ªë chi·ªÅu ƒë·∫ßu ra"):
                        st.write("**N·∫øu ch·ªçn 2**: 2D ‚Üí D·ªÖ v·∫Ω bi·ªÉu ƒë·ªì tr√™n m·∫∑t ph·∫≥ng. Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ kho·∫£ng [0,1] ho·∫∑c [-1,1], gi√∫p duy tr√¨ t·ª∑ l·ªá gi·ªØa c√°c gi√° tr·ªã g·ªëc.")
                        st.write("**N·∫øu ch·ªçn 3**: 3D ‚Üí Hi·ªÉn th·ªã t·ªët h∆°n v·ªõi d·ªØ li·ªáu ph·ª©c t·∫°p. Bi·∫øn ƒë·ªïi d·ªØ li·ªáu v·ªÅ trung b√¨nh 0 v√† ƒë·ªô l·ªách chu·∫©n 1, ph√π h·ª£p v·ªõi d·ªØ li·ªáu c√≥ ph√¢n ph·ªëi chu·∫©n.")   
                    perplexity = st.slider("**Perplexity:**", min_value=5, max_value=50, value=30)
                    learning_rate = st.slider("**Learning rate:**", min_value=10, max_value=1000, value=200)
                    n_iter = st.slider("**S·ªë v√≤ng l·∫∑p t·ªëi ƒëa:**", min_value=250, max_value=5000, value=1000, step=250)
                    metric = st.selectbox("**Kho·∫£ng c√°ch:**", ["euclidean", "cosine", "manhattan"])

                    if st.button("üöÄ Ch·∫°y t-SNE"):
                        with mlflow.start_run():
                            # √Åp d·ª•ng t-SNE
                            tsne = TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate, 
                                        n_iter=n_iter, metric=metric, random_state=42)
                            X_train_tsne = tsne.fit_transform(X_train_scaled)
                            st.session_state.X_train_tsne = X_train_tsne
                            try:
                                st.session_state.kl_divergence = tsne.kl_divergence_
                            except AttributeError:
                                st.session_state.kl_divergence = "Kh√¥ng c√≥ th√¥ng tin"
                            mlflow.log_param("algorithm", "t-SNE")
                            mlflow.log_param("n_components", n_components)
                            mlflow.log_param("perplexity", perplexity)
                            mlflow.log_param("learning_rate", learning_rate)
                            mlflow.log_param("n_iter", n_iter)
                            mlflow.log_param("metric", metric)
                            
                            mlflow.log_param("X_train_tsne",X_train_tsne)
                            
                            fig, ax = plt.subplots(figsize=(6, 4))
                            scatter = ax.scatter(X_train_tsne[:, 0], X_train_tsne[:, 1], alpha=0.5, cmap="coolwarm")
                            ax.set_title(f"t-SNE v·ªõi Perplexity={perplexity}")
                            st.pyplot(fig)

                            fig.savefig("tsne_result.png")
                            mlflow.log_artifact("tsne_result.png")

                            st.markdown(
                                f"""
                                ### K·∫øt qu·∫£ t-SNE:
                                - D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c gi·∫£m chi·ªÅu xu·ªëng {n_components} chi·ªÅu ƒë·ªÉ tr·ª±c quan h√≥a.  
                                - **t-SNE** gi√∫p gi·ªØ l·∫°i c·∫•u tr√∫c c·ª•c b·ªô c·ªßa d·ªØ li·ªáu, th√≠ch h·ª£p cho d·ªØ li·ªáu phi tuy·∫øn t√≠nh.
                                """
                            )
                        mlflow.end_run()


                            

    with tab_split:
        with st.expander(" ƒê√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh ph√¢n c·ª•m", expanded=True):
            if "X_train_pca" in st.session_state and "explained_variance_ratio_" in st.session_state:
                X_reduced = st.session_state.X_train_pca
                explained_var = st.session_state.explained_variance_ratio_

                st.markdown("### PCA (Principal Component Analysis)")
                st.markdown("---")
                st.write(f"‚úÖ **Explained Variance Ratio:** {explained_var}")
                total_explained = np.sum(explained_var) * 100

                # T·∫°o chu·ªói gi·∫£i th√≠ch ƒë·ªông d·ª±a tr√™n gi√° tr·ªã th·ª±c t·∫ø
                explanation = "**Gi·∫£i th√≠ch:**\n"
                for i, var in enumerate(explained_var):
                    explanation += f"- Th√†nh ph·∫ßn ch√≠nh th·ª© {i+1} gi·∫£i th√≠ch **{var*100:.2f}%** ph∆∞∆°ng sai.\n"
                st.markdown(explanation)
                st.write(f"‚úÖ **T·ªïng ph∆∞∆°ng sai gi·∫£i th√≠ch:** {np.sum(explained_var):.4f}")

                # V·∫Ω bi·ªÉu ƒë·ªì tr·ª±c quan h√≥a d·ªØ li·ªáu PCA
                fig, ax = plt.subplots(figsize=(6, 4))
                ax.scatter(X_reduced[:, 0], X_reduced[:, 1], alpha=0.6, marker='o', c='blue')
                ax.set_title("Ph√¢n b·ªë d·ªØ li·ªáu sau PCA")
                ax.set_xlabel("Th√†nh ph·∫ßn 1")
                ax.set_ylabel("Th√†nh ph·∫ßn 2")
                st.pyplot(fig)

            # Ki·ªÉm tra xem d·ªØ li·ªáu t-SNE c√≥ t·ªìn t·∫°i kh√¥ng
            elif "X_train_tsne" in st.session_state:
                X_reduced = st.session_state.X_train_tsne
                kl_divergence = st.session_state.get("kl_divergence", "Kh√¥ng c√≥ th√¥ng tin")

                st.markdown("### t-SNE (t-Distributed Stochastic Neighbor Embedding)")
                st.markdown("---")
                st.write(f"‚úÖ **KL Divergence:** {kl_divergence}")
                st.markdown("""
                - KL Divergence th·∫•p cho th·∫•y t-SNE h·ªôi t·ª• t·ªët.
                - KL Divergence cao c√≥ th·ªÉ do perplexity kh√¥ng ph√π h·ª£p ho·∫∑c d·ªØ li·ªáu ph·ª©c t·∫°p.
                """)

                # V·∫Ω bi·ªÉu ƒë·ªì t-SNE
                fig, ax = plt.subplots(figsize=(6, 4))
                ax.scatter(X_reduced[:, 0], X_reduced[:, 1], alpha=0.6, marker='o', c='green')
                ax.set_title("Ph√¢n b·ªë d·ªØ li·ªáu sau t-SNE")
                ax.set_xlabel("Th√†nh ph·∫ßn 1")
                ax.set_ylabel("Th√†nh ph·∫ßn 2")
                st.pyplot(fig)
            else:
                st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu gi·∫£m chi·ªÅu ƒë·ªÉ ƒë√°nh gi√°!")

            # So s√°nh c·∫•u tr√∫c d·ªØ li·ªáu tr∆∞·ªõc v√† sau gi·∫£m chi·ªÅu
            if "X_train_scaled" in st.session_state and ("X_train_pca" in st.session_state or "X_train_tsne" in st.session_state):
                X_original = st.session_state.X_train_scaled  # D·ªØ li·ªáu g·ªëc
                original_distances = pairwise_distances(X_original[:500])
                reduced_distances = pairwise_distances(X_reduced[:500])
                correlation = np.corrcoef(original_distances.flatten(), reduced_distances.flatten())[0, 1]
                st.write(f"‚úÖ **T∆∞∆°ng quan kho·∫£ng c√°ch tr∆∞·ªõc v√† sau gi·∫£m chi·ªÅu:** {correlation:.4f}")

            else:
                st.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu gi·∫£m chi·ªÅu ƒë·ªÉ ƒë√°nh gi√°!")
    with tab_mlflow:
        st.header("Th√¥ng tin Hu·∫•n luy·ªán & MLflow UI")
        try:  
            client = MlflowClient()
            experiment_name = "MyExperiment"
    
            # Ki·ªÉm tra n·∫øu experiment ƒë√£ t·ªìn t·∫°i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment m·ªõi ƒë∆∞·ª£c t·∫°o v·ªõi ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"ƒêang s·ª≠ d·ª•ng experiment ID: {experiment_id}")
    
            mlflow.set_experiment(experiment_name)
    
            # Truy v·∫•n c√°c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])
    
            # 1) Ch·ªçn v√† ƒë·ªïi t√™n Run Name
            st.subheader("ƒê·ªïi t√™n Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                               for run in runs}
                selected_run_id_for_rename = st.selectbox("Ch·ªçn Run ƒë·ªÉ ƒë·ªïi t√™n:", 
                                                          options=list(run_options.keys()), 
                                                          format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi cho Run:", 
                                             value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("C·∫≠p nh·∫≠t t√™n Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ c·∫≠p nh·∫≠t t√™n Run th√†nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui l√≤ng nh·∫≠p t√™n m·ªõi cho Run.")
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log.")
    
            # 2) X√≥a Run
            st.subheader("Danh s√°ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                         options=list(run_options.keys()), 
                                                         format_func=lambda x: run_options[x])
                if st.button("X√≥a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ƒê√£ x√≥a Run {run_options[selected_run_id_to_delete]} th√†nh c√¥ng!")
                    st.experimental_rerun()  # T·ª± ƒë·ªông l√†m m·ªõi giao di·ªán
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë·ªÉ x√≥a.")
    
            # 3) Danh s√°ch c√°c th√≠ nghi·ªám
            st.subheader("Danh s√°ch c√°c Run ƒë√£ log")
            if runs:
                selected_run_id = st.selectbox("Ch·ªçn Run ƒë·ªÉ xem chi ti·∫øt:", 
                                               options=list(run_options.keys()), 
                                               format_func=lambda x: run_options[x])
    
                # 4) Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa Run ƒë∆∞·ª£c ch·ªçn
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
    
                st.markdown("### Tham s·ªë ƒë√£ log")
                st.json(selected_run.data.params)
    
                st.markdown("### Ch·ªâ s·ªë ƒë√£ log")
                metrics = {
                    "n_components": selected_run.data.metrics.get("n_components", "N/A"),
                    "perplexity": selected_run.data.metrics.get("perplexity", "N/A"),
                    "learning_rate": selected_run.data.metrics.get("learning_rate", "N/A"),
                    "n_iter": selected_run.data.metrics.get("n_iter", "N/A"),
                    "metric": selected_run.data.metrics.get("metric", "N/A"),
                    "svd_solver": selected_run.data.metrics.get("svd_solver", "N/A"),
                    "whiten": selected_run.data.metrics.get("whiten", "N/A")
                }
                st.json(metrics)
    
                # 5) N√∫t b·∫•m m·ªü MLflow UI
                st.subheader("Truy c·∫≠p MLflow UI")
                mlflow_url = "https://dagshub.com/Dung2204/HMVPython.mlflow"
                if st.button("M·ªü MLflow UI"):
                    st.markdown(f'**[Click ƒë·ªÉ m·ªü MLflow UI]({mlflow_url})**')
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
    
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow: {e}")    

if __name__ == "__main__":
    run_PcaTSNEMinst_app()  


# st.write(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
# with st.expander("üñºÔ∏è ƒê√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh ph√¢n c·ª•m", expanded=True):
#     # st.write(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
#     print("üéØ Ki·ªÉm tra tr√™n DagsHub: https://dagshub.com/Dung2204/Minst-mlflow.mlflow")


# # # # cd "C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App"
