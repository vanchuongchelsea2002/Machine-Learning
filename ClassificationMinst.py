
import streamlit as st
import os
import cv2
import numpy as np
import pandas as pd
import pickle
import seaborn as sns
import random
import struct
from sklearn.datasets import load_iris
import mlflow
import matplotlib.pyplot as plt
from streamlit_drawable_canvas import st_canvas
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier,plot_tree
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay
from PIL import Image
from sklearn.model_selection import KFold
from collections import Counter
from mlflow.tracking import MlflowClient

def run_ClassificationMinst_app():
    @st.cache_data  # L∆∞u cache ƒë·ªÉ tr√°nh load l·∫°i d·ªØ li·ªáu m·ªói l·∫ßn ch·∫°y l·∫°i Streamlit
    def get_sampled_pixels(images, sample_size=100_000):
        return np.random.choice(images.flatten(), sample_size, replace=False)

    @st.cache_data  # Cache danh s√°ch ·∫£nh ng·∫´u nhi√™n
    def get_random_indices(num_images, total_images):
        return np.random.randint(0, total_images, size=num_images)

    # C·∫•u h√¨nh Streamlit    
    # st.set_page_config(page_title="Ph√¢n lo·∫°i ·∫£nh", layout="wide")
    # ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ ƒë·ªçc file .idx
    def load_mnist_images(filename):
        with open(filename, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
        return images

    def load_mnist_labels(filename):
        with open(filename, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            labels = np.fromfile(f, dtype=np.uint8)
        return labels

    mlflow_tracking_uri = st.secrets["MLFLOW_TRACKING_URI"]
    mlflow_username = st.secrets["MLFLOW_TRACKING_USERNAME"]
    mlflow_password = st.secrets["MLFLOW_TRACKING_PASSWORD"]
    
    # Thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng
    os.environ["MLFLOW_TRACKING_URI"] = mlflow_tracking_uri
    os.environ["MLFLOW_TRACKING_USERNAME"] = mlflow_username
    os.environ["MLFLOW_TRACKING_PASSWORD"] = mlflow_password
    
    # Thi·∫øt l·∫≠p MLflow (ƒê·∫∑t sau khi mlflow_tracking_uri ƒë√£ c√≥ gi√° tr·ªã)
    mlflow.set_tracking_uri(mlflow_tracking_uri)



    # ƒê·ªãnh nghƒ©a ƒë∆∞·ªùng d·∫´n ƒë·∫øn c√°c file MNIST
    dataset_path = os.path.dirname(os.path.abspath(__file__)) 
    train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
    train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
    test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
    test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

    # T·∫£i d·ªØ li·ªáu
    train_images = load_mnist_images(train_images_path)
    train_labels = load_mnist_labels(train_labels_path)
    test_images = load_mnist_images(test_images_path)
    test_labels = load_mnist_labels(test_labels_path)

    # Giao di·ªán Streamlit
    st.title("üì∏ Ph√¢n lo·∫°i ·∫£nh MNIST v·ªõi Streamlit")
    tabs = st.tabs([
        "Th√¥ng tin d·ªØ li·ªáu",
        "Th√¥ng tin",
        "X·ª≠ l√≠ d·ªØ li·ªáu",
        "Hu·∫•n luy·ªán m√¥ h√¨nh",
        "Demo d·ª± ƒëo√°n",
        "Th√¥ng tin & Mlflow",
    ])
    # tab_info, tab_load, tab_preprocess, tab_split,  tab_demo, tab_log_info = tabs
    tab_info,tab_note,tab_load, tab_preprocess,  tab_demo ,tab_mlflow= tabs

    # with st.expander("üñºÔ∏è D·ªØ li·ªáu ban ƒë·∫ßu", expanded=True):
    with tab_info:
        with st.expander("**Th√¥ng tin d·ªØ li·ªáu**", expanded=True):
            st.markdown(
                '''
                **MNIST** l√† phi√™n b·∫£n ƒë∆∞·ª£c ch·ªânh s·ª≠a t·ª´ b·ªô d·ªØ li·ªáu NIST g·ªëc c·ªßa Vi·ªán Ti√™u chu·∫©n v√† C√¥ng ngh·ªá Qu·ªëc gia Hoa K·ª≥.  
                B·ªô d·ªØ li·ªáu ban ƒë·∫ßu g·ªìm c√°c ch·ªØ s·ªë vi·∫øt tay t·ª´ nh√¢n vi√™n b∆∞u ƒëi·ªán v√† h·ªçc sinh trung h·ªçc.  

                C√°c nh√† nghi√™n c·ª©u **Yann LeCun, Corinna Cortes, v√† Christopher Burges** ƒë√£ x·ª≠ l√Ω, chu·∫©n h√≥a v√† chuy·ªÉn ƒë·ªïi b·ªô d·ªØ li·ªáu n√†y th√†nh **MNIST** ƒë·ªÉ d·ªÖ d√†ng s·ª≠ d·ª•ng h∆°n cho c√°c b√†i to√°n nh·∫≠n d·∫°ng ch·ªØ s·ªë vi·∫øt tay.
                '''
            )
            # image = Image.open(r'C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App\image.png')

            # G·∫Øn ·∫£nh v√†o Streamlit v√† ch·ªânh k√≠ch th∆∞·ªõc
            # st.image(image, caption='M√¥ t·∫£ ·∫£nh', width=600) 
            # ƒê·∫∑c ƒëi·ªÉm c·ªßa b·ªô d·ªØ li·ªáu
        with st.expander("**ƒê·∫∑c ƒëi·ªÉm c·ªßa b·ªô d·ªØ li·ªáu**", expanded=True):
            st.markdown(
                '''
                - **S·ªë l∆∞·ª£ng ·∫£nh:** 70.000 ·∫£nh ch·ªØ s·ªë vi·∫øt tay  
                - **K√≠ch th∆∞·ªõc ·∫£nh:** M·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc 28x28 pixel  
                - **C∆∞·ªùng ƒë·ªô ƒëi·ªÉm ·∫£nh:** T·ª´ 0 (m√†u ƒëen) ƒë·∫øn 255 (m√†u tr·∫Øng)  
                - **D·ªØ li·ªáu nh√£n:** M·ªói ·∫£nh ƒëi k√®m v·ªõi m·ªôt nh√£n s·ªë t·ª´ 0 ƒë·∫øn 9  
                '''
            )
            st.write(f"üîç S·ªë l∆∞·ª£ng ·∫£nh hu·∫•n luy·ªán: `{train_images.shape[0]}`")
            st.write(f"üîç S·ªë l∆∞·ª£ng ·∫£nh ki·ªÉm tra: `{test_images.shape[0]}`")

        with st.expander("**Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u c·ªßa t·ª´ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9 trong t·∫≠p hu·∫•n luy·ªán**", expanded=True):
            label_counts = pd.Series(train_labels).value_counts().sort_index()

            # # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì c·ªôt
            # st.subheader("üìä Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng m·∫´u c·ªßa t·ª´ng ch·ªØ s·ªë")
            # st.bar_chart(label_counts)

            # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu d∆∞·ªõi bi·ªÉu ƒë·ªì
            st.subheader("üìã S·ªë l∆∞·ª£ng m·∫´u cho t·ª´ng ch·ªØ s·ªë")
            df_counts = pd.DataFrame({"Ch·ªØ s·ªë": label_counts.index, "S·ªë l∆∞·ª£ng m·∫´u": label_counts.values})
            st.dataframe(df_counts)


            st.subheader("Ch·ªçn ng·∫´u nhi√™n 10 ·∫£nh t·ª´ t·∫≠p hu·∫•n luy·ªán ƒë·ªÉ hi·ªÉn th·ªã")
            num_images = 10
            random_indices = random.sample(range(len(train_images)), num_images)
            fig, axes = plt.subplots(1, num_images, figsize=(10, 5))

            for ax, idx in zip(axes, random_indices):
                ax.imshow(train_images[idx], cmap='gray')
                ax.axis("off")
                ax.set_title(f"Label: {train_labels[idx]}")

            st.pyplot(fig)
        with st.expander("**Ki·ªÉm tra h√¨nh d·∫°ng c·ªßa t·∫≠p d·ªØ li·ªáu**", expanded=True):    
            # Ki·ªÉm tra h√¨nh d·∫°ng c·ªßa t·∫≠p d·ªØ li·ªáu
            st.write("üîç H√¨nh d·∫°ng t·∫≠p hu·∫•n luy·ªán:", train_images.shape)
            st.write("üîç H√¨nh d·∫°ng t·∫≠p ki·ªÉm tra:", test_images.shape)
            st.write("**Chu·∫©n h√≥a d·ªØ li·ªáu (ƒë∆∞a gi√° tr·ªã pixel v·ªÅ kho·∫£ng 0-1)**")
            # Chu·∫©n h√≥a d·ªØ li·ªáu
            train_images = train_images.astype("float32") / 255.0
            test_images = test_images.astype("float32") / 255.0

            # Hi·ªÉn th·ªã th√¥ng b√°o sau khi chu·∫©n h√≥a
            st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ kho·∫£ng [0,1].") 

            # Hi·ªÉn th·ªã b·∫£ng d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a (d·∫°ng s·ªë)
            num_samples = 5  # S·ªë l∆∞·ª£ng m·∫´u hi·ªÉn th·ªã
            df_normalized = pd.DataFrame(train_images[:num_samples].reshape(num_samples, -1))  

            
            sample_size = 10_000  
            pixel_sample = np.random.choice(train_images.flatten(), sample_size, replace=False)
            if "train_images" not in st.session_state:
                st.session_state.train_images = train_images
                st.session_state.train_labels = train_labels
                st.session_state.test_images = test_images
                st.session_state.test_labels = test_labels


    with tab_note:
        with st.expander("**Th√¥ng tin m√¥ h√¨nh**", expanded=True):    
            # Assume model_option1 is selected from somewhere in the app
            model_option1 = st.selectbox("Ch·ªçn m√¥ h√¨nh", ["Decision Tree", "SVM"])
            if model_option1 == "Decision Tree":
                
                st.markdown("""
                ### Decision Tree (C√¢y quy·∫øt ƒë·ªãnh)
                """)
                st.markdown("---")
                st.markdown("""
                ### Kh√°i ni·ªám:  
                **Decision Tree (C√¢y quy·∫øt ƒë·ªãnh)**:
                - **Decision Tree (C√¢y quy·∫øt ƒë·ªãnh)** l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y s·ª≠ d·ª•ng c·∫•u tr√∫c d·∫°ng c√¢y ƒë·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh ph√¢n lo·∫°i ho·∫∑c d·ª± ƒëo√°n gi√° tr·ªã li√™n t·ª•c. 
                - N√≥ ho·∫°t ƒë·ªông b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p con nh·ªè h∆°n d·ª±a tr√™n gi√° tr·ªã c·ªßa c√°c ƒë·∫∑c tr∆∞ng, v·ªõi m·ªói n√∫t trong c√¢y ƒë·∫°i di·ªán cho m·ªôt ƒëi·ªÅu ki·ªán ki·ªÉm tra, m·ªói nh√°nh l√† k·∫øt qu·∫£ c·ªßa ƒëi·ªÅu ki·ªán ƒë√≥, v√† m·ªói l√° c√¢y l√† k·∫øt qu·∫£ cu·ªëi c√πng (nh√£n l·ªõp ho·∫∑c gi√° tr·ªã d·ª± ƒëo√°n).

                **C√°ch ho·∫°t ƒë·ªông**:  
                - **C√¢y quy·∫øt ƒë·ªãnh** b·∫Øt ƒë·∫ßu t·ª´ n√∫t g·ªëc (root), ki·ªÉm tra m·ªôt ƒë·∫∑c tr∆∞ng c·ªßa d·ªØ li·ªáu, v√† ph√¢n chia d·ªØ li·ªáu th√†nh c√°c nh√°nh con d·ª±a tr√™n k·∫øt qu·∫£ ki·ªÉm tra. 
                - Qu√° tr√¨nh n√†y l·∫∑p l·∫°i cho ƒë·∫øn khi d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n chia ho√†n to√†n ho·∫∑c ƒë·∫°t ƒë·∫øn ƒëi·ªÅu ki·ªán d·ª´ng (v√≠ d·ª•: ƒë·ªô s√¢u t·ªëi ƒëa). 
                - Thu·∫≠t to√°n th∆∞·ªùng s·ª≠ d·ª•ng c√°c ti√™u ch√≠ nh∆∞ ƒë·ªô thu·∫ßn nh·∫•t ƒë·ªÉ ch·ªçn ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t cho m·ªói l·∫ßn ph√¢n chia.
                """)
                st.markdown("---")
                st.markdown("""
                ### C√¥ng th·ª©c to√°n h·ªçc:  
                **Entropy**: 
                -ƒêo l∆∞·ªùng ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn c·ªßa t·∫≠p d·ªØ li·ªáu:  
                $$
                H(S) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)
                $$
                Trong ƒë√≥:  
                - $$(S)$$: T·∫≠p d·ªØ li·ªáu.  
                - $$(c)$$: S·ªë l·ªõp.  
                - $$(p_i)$$: T·ª∑ l·ªá m·∫´u thu·ªôc l·ªõp \(i\).  

                **Information Gain**: ƒêo l∆∞·ªùng m·ª©c ƒë·ªô gi·∫£m **entropy** sau khi ph√¢n chia:  
                $$
                IG(S, A) = H(S) - \\sum_{j=1}^{k} \\frac{|S_v|}{|S|} H(S_v)
                $$
                Trong ƒë√≥:  
                - $$(A)$$: ƒê·∫∑c tr∆∞ng ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ ph√¢n chia.  
                - $$(S_v)$$: T·∫≠p con c·ªßa \(S\) v·ªõi gi√° tr·ªã \(v\) c·ªßa ƒë·∫∑c tr∆∞ng \(A\).  
                """)
                st.markdown("---")
                st.markdown("""
                ### Ho·∫°t ƒë·ªông tr√™n MNIST:  
                V·ªõi b·ªô d·ªØ li·ªáu **MNIST** (·∫£nh ch·ªØ s·ªë vi·∫øt tay 28x28, 10 l·ªõp t·ª´ 0-9), Decision Tree s·∫Ω:  
                - M·ªói ·∫£nh trong **MNIST** c√≥ k√≠ch th∆∞·ªõc 28√ó28 pixels, m·ªói pixel c√≥ th·ªÉ xem l√† m·ªôt ƒë·∫∑c tr∆∞ng (feature).
                - M√¥ h√¨nh s·∫Ω quy·∫øt ƒë·ªãnh ph√¢n t√°ch d·ªØ li·ªáu b·∫±ng c√°ch ch·ªçn nh·ªØng pixels quan tr·ªçng nh·∫•t ƒë·ªÉ t·∫°o nh√°nh.
                - V√≠ d·ª•, ƒë·ªÉ ph√¢n bi·ªát ch·ªØ s·ªë 0 v√† 1, **Decision Tree** c√≥ th·ªÉ ki·ªÉm tra:
                    - Pixel ·ªü gi·ªØa c√≥ s√°ng kh√¥ng?
                    - Pixel d·ªçc hai b√™n c√≥ s√°ng kh√¥ng?
                - D·ª±a tr√™n c√¢u tr·∫£ l·ªùi, m√¥ h√¨nh s·∫Ω ti·∫øp t·ª•c chia nh·ªè t·∫≠p d·ªØ li·ªáu.
                """)
                st.markdown("""
                ### √Åp d·ª•ng v√†o ng·ªØ c·∫£nh Decision Tree v·ªõi MNIST:
                - **Entropy** gi√∫p **Decision Tree** ƒë√°nh gi√° m·ª©c ƒë·ªô h·ªón lo·∫°n c·ªßa d·ªØ li·ªáu **MNIST** (v√≠ d·ª•: t·∫≠p h·ª£p c√°c ·∫£nh ch·ªØ s·ªë 0-9 c√≥ t·ª∑ l·ªá ph√¢n b·ªë nh∆∞ th·∫ø n√†o).
                - **Information Gain** ƒë∆∞·ª£c d√πng ƒë·ªÉ ch·ªçn c√°c pixel (ƒë·∫∑c tr∆∞ng) quan tr·ªçng nh·∫•t (v√≠ d·ª•: pixel s√°ng/t·ªëi ·ªü v·ªã tr√≠ n√†o) ƒë·ªÉ ph√¢n chia d·ªØ li·ªáu, t·ª´ ƒë√≥ x√¢y d·ª±ng c√¢y ph√¢n lo·∫°i c√°c ch·ªØ s·ªë hi·ªáu qu·∫£.
                """)
                
                st.markdown("---")
                st.markdown("### V√≠ d·ª• v·ªÅ Decision TreeTree: minh h·ªça m√¥ h√¨nh ph√¢n lo·∫°i d·ªØ li·ªáu hoa Iris")
                # T·∫£i b·ªô d·ªØ li·ªáu Iris t·ª´ sklearn
                iris = load_iris()
                X, y = iris.data, iris.target

                # Hu·∫•n luy·ªán m√¥ h√¨nh c√¢y quy·∫øt ƒë·ªãnh
                clf = DecisionTreeClassifier(max_depth=3, random_state=42)
                clf.fit(X, y)

                # V·∫Ω bi·ªÉu ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh
                fig, ax = plt.subplots(figsize=(12, 8))
                plot_tree(clf, feature_names=iris.feature_names, class_names=iris.target_names, filled=True, ax=ax)

                # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì tr√™n Streamlit
                st.pyplot(fig)
                st.markdown("""
                üìù Gi·∫£i th√≠ch v·ªÅ c√¢y quy·∫øt ƒë·ªãnh v√≠ d·ª• tr√™n:
                - **C√°c n√∫t (Nodes)**: M·ªói h√¨nh ch·ªØ nh·∫≠t l√† m·ªôt n√∫t quy·∫øt ƒë·ªãnh d·ª±a tr√™n m·ªôt ƒë·∫∑c tr∆∞ng c·ªßa d·ªØ li·ªáu.
                - **Nh√°nh (Branches)**: C√°c ƒë∆∞·ªùng n·ªëi th·ªÉ hi·ªán k·∫øt qu·∫£ c·ªßa ƒëi·ªÅu ki·ªán ki·ªÉm tra.
                - **Samples**: S·ªë l∆∞·ª£ng m·∫´u t·∫°i m·ªói n√∫t.
                - **Class**: Nh√£n ƒë∆∞·ª£c d·ª± ƒëo√°n t·∫°i n√∫t l√°.

                Bi·ªÉu ƒë·ªì tr√™n th·ªÉ hi·ªán c√°ch m√¥ h√¨nh ph√¢n lo·∫°i d·ªØ li·ªáu hoa Iris d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng nh∆∞ chi·ªÅu d√†i c√°nh hoa ho·∫∑c ƒë√†i hoa.
                """)

            elif model_option1 == "SVM":
                st.markdown("""
                ### Support Vector Machine (SVM)
                """)    
                st.markdown("---")        
                st.markdown("""            
                ### Kh√°i ni·ªám:  
                **Support Vector Machine (SVM)**:
                - L√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y m·∫°nh m·∫Ω, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng cho b√†i to√°n ph√¢n lo·∫°i (ƒë·∫∑c bi·ªát l√† ph√¢n lo·∫°i nh·ªã ph√¢n) ho·∫∑c h·ªìi quy. 
                - √ù t∆∞·ªüng ch√≠nh c·ªßa **SVM** l√† t√¨m m·ªôt si√™u ph·∫≥ng (hyperplane) trong kh√¥ng gian ƒëa chi·ªÅu ƒë·ªÉ ph√¢n chia c√°c l·ªõp d·ªØ li·ªáu sao cho kho·∫£ng c√°ch t·ª´ si√™u ph·∫≥ng ƒë·∫øn c√°c ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t (**support vectors**) l√† l·ªõn nh·∫•t c√≥ th·ªÉ.

                **C√°ch ho·∫°t ƒë·ªông**:  
                - **SVM** c·ªë g·∫Øng t·ªëi ∆∞u h√≥a ranh gi·ªõi ph√¢n chia gi·ªØa c√°c l·ªõp b·∫±ng c√°ch t·ªëi ƒëa h√≥a "kho·∫£ng c√°ch l·ªÅ" (margin) gi·ªØa si√™u ph·∫≥ng v√† c√°c ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t. 
                - Trong tr∆∞·ªùng h·ª£p d·ªØ li·ªáu kh√¥ng th·ªÉ ph√¢n chia tuy·∫øn t√≠nh, SVM s·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ bi·∫øn ƒë·ªïi kh√¥ng gian (th√¥ng qua kernel) ƒë·ªÉ ƒë∆∞a d·ªØ li·ªáu v√†o kh√¥ng gian cao h∆°n, n∆°i c√≥ th·ªÉ ph√¢n chia ƒë∆∞·ª£c.
                """) 
                st.markdown("---")          
                st.markdown("""
                ### C√¥ng th·ª©c to√°n h·ªçc:  
                **Si√™u ph·∫≥ng**:
                - **Si√™u ph·∫≥ng** ƒë√≥ng vai tr√≤ l√†m ranh gi·ªõi quy·∫øt ƒë·ªãnh, ph√¢n chia c√°c l·ªõp d·ªØ li·ªáu (v√≠ d·ª•: l·ªõp 0 v√† l·ªõp 1) trong kh√¥ng gian ƒë·∫∑c tr∆∞ng, ƒë·∫£m b·∫£o kho·∫£ng c√°ch l·ªõn nh·∫•t ƒë·∫øn c√°c ƒëi·ªÉm g·∫ßn nh·∫•t.
                - ƒê∆∞·ª£c ƒë·ªãnh nghƒ©a b·ªüi ph∆∞∆°ng tr√¨nh:  
                $$
                w^T x + b = 0
                $$
                Trong ƒë√≥:  
                - \(w\): Vector tr·ªçng s·ªë (vu√¥ng g√≥c v·ªõi si√™u ph·∫≥ng).  
                - \(x\): Vector ƒë·∫∑c tr∆∞ng.  
                - \(b\): ƒê·ªô l·ªách (bias).  

                **T·ªëi ∆∞u h√≥a l·ªÅ**: 
                - **T·ªëi ∆∞u h√≥a l·ªÅ** l√† b√†i to√°n t·ªëi ∆∞u h√≥a nh·∫±m t√¨m **si√™u ph·∫≥ng** t·ªët nh·∫•t, t·ªëi ƒëa h√≥a margin (kho·∫£ng c√°ch gi·ªØa si√™u ph·∫≥ng v√† c√°c support vectors) b·∫±ng c√°ch gi·∫£m thi·ªÉu ƒë·ªô d√†i vector \(w\), ƒë·ªìng th·ªùi ƒë·∫£m b·∫£o t·∫•t c·∫£ c√°c ƒëi·ªÉm d·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n lo·∫°i ƒë√∫ng.
                - ƒê∆∞·ª£c ƒë·ªãnh nghƒ©a b·ªüi ph∆∞∆°ng tr√¨nh:  
                $$
                \\min_{w, b} \\frac{1}{2} ||w||^2 \\quad \\text{v·ªõi ƒëi·ªÅu ki·ªán} \\quad y_i (w^T x_i + b) \\geq 1, \\forall i
                $$
                Trong ƒë√≥:  
                - $$(||w||)$$: ƒê·ªô d√†i vector \(w\).
                - $$(y_i)$$: Nh√£n c·ªßa m·∫´u \(i\) (\(+1\) ho·∫∑c \(-1\)).  
                - $$(x_i)$$: Vector ƒë·∫∑c tr∆∞ng c·ªßa m·∫´u \(i\).  

                **Kernel Trick**: Khi d·ªØ li·ªáu kh√¥ng tuy·∫øn t√≠nh, s·ª≠ d·ª•ng h√†m kernel $$(K(x_i, x_j))$$ ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu v√†o kh√¥ng gian cao h∆°n.
                """)           
                st.markdown("---")
                st.markdown("""  
                ### √Åp d·ª•ng v√†o ng·ªØ c·∫£nh SVM v·ªõi MNIST:  
                - Trong th·ª±c t·∫ø, tr∆∞·ªõc khi √°p d·ª•ng SVM tr√™n MNIST, d·ªØ li·ªáu th∆∞·ªùng ƒë∆∞·ª£c chu·∫©n h√≥a (v√≠ d·ª•: chia gi√° tr·ªã pixel cho 255 ƒë·ªÉ ƒë∆∞a v·ªÅ kho·∫£ng [0, 1]) ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa kernel v√† tr√°nh c√°c v·∫•n ƒë·ªÅ s·ªë h·ªçc.  
                - Do MNIST c√≥ 70,000 m·∫´u (60,000 hu·∫•n luy·ªán v√† 10,000 ki·ªÉm tra) v·ªõi 784 ƒë·∫∑c tr∆∞ng (28x28 pixel), SVM c√≥ th·ªÉ y√™u c·∫ßu gi·∫£m chi·ªÅu d·ªØ li·ªáu (v√≠ d·ª•: s·ª≠ d·ª•ng PCA) ho·∫∑c t·ªëi ∆∞u h√≥a tham s·ªë (nh∆∞ \(C\) v√† \(\gamma\) trong kernel RBF) ƒë·ªÉ gi·∫£m ƒë·ªô ph·ª©c t·∫°p t√≠nh to√°n v√† tƒÉng ƒë·ªô ch√≠nh x√°c.  
                - SVM tr√™n MNIST th∆∞·ªùng s·ª≠ d·ª•ng chi·∫øn l∆∞·ª£c One-vs-Rest ho·∫∑c One-vs-One ƒë·ªÉ x·ª≠ l√Ω 10 l·ªõp, v·ªõi kernel RBF l√† l·ª±a ch·ªçn ph·ªï bi·∫øn do t√≠nh phi tuy·∫øn c·ªßa d·ªØ li·ªáu. Tuy nhi√™n, v·ªõi d·ªØ li·ªáu l·ªõn v√† ph·ª©c t·∫°p nh∆∞ MNIST, c√°c m√¥ h√¨nh nh∆∞ Convolutional Neural Networks (CNN) th∆∞·ªùng hi·ªáu qu·∫£ h∆°n, nh∆∞ng SVM v·∫´n c√≥ th·ªÉ √°p d·ª•ng tr√™n t·∫≠p con nh·ªè h∆°n ho·∫∑c sau khi gi·∫£m chi·ªÅu.
                """)

                st.markdown("---")
                st.markdown("### V√≠ d·ª• v·ªÅ SVM: minh h·ªça v·ªÅ ranh gi·ªõi quy·∫øt ƒë·ªãnh (decision boundary)")
                X = np.array([[1, 2], [2, 3], [3, 3], [6, 5], [7, 8], [8, 8]])  # 6 ƒëi·ªÉm (x, y)
                y = np.array([0, 0, 0, 1, 1, 1])  # Nh√£n (0 ho·∫∑c 1)

                # Hu·∫•n luy·ªán m√¥ h√¨nh SVM
                model = SVC(kernel="linear")
                model.fit(X, y)

                # T·∫°o bi·ªÉu ƒë·ªì
                fig, ax = plt.subplots()
                ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')

                # V·∫Ω ƒë∆∞·ªùng ph√¢n chia
                xlim = ax.get_xlim()
                ylim = ax.get_ylim()

                # T·∫°o l∆∞·ªõi ƒëi·ªÉm ƒë·ªÉ v·∫Ω ranh gi·ªõi
                xx = np.linspace(xlim[0], xlim[1], 30)
                yy = np.linspace(ylim[0], ylim[1], 30)
                YY, XX = np.meshgrid(yy, xx)
                xy = np.vstack([XX.ravel(), YY.ravel()]).T
                Z = model.decision_function(xy).reshape(XX.shape)

                # V·∫Ω ranh gi·ªõi quy·∫øt ƒë·ªãnh c·ªßa SVM
                ax.contour(XX, YY, Z, colors='k', levels=[0], linestyles=['--'])

                ax.set_xlabel("X1")
                ax.set_ylabel("X2")
                # Hi·ªÉn th·ªã tr√™n Streamlit
                st.pyplot(fig)
                st.markdown("""
                üìù Gi·∫£i th√≠ch v·ªÅ bi·ªÉu ƒë·ªì SVM v√≠ d·ª• tr√™n:
                - C√°c **ƒëi·ªÉm tr√≤n** ƒë·∫°i di·ªán cho d·ªØ li·ªáu, v·ªõi m√†u s·∫Øc kh√°c nhau bi·ªÉu th·ªã hai l·ªõp.
                - ƒê∆∞·ªùng **ƒë·ª©t n√©t** l√† ranh gi·ªõi quy·∫øt ƒë·ªãnh (si√™u ph·∫≥ng) ph√¢n chia hai l·ªõp.
                - **ƒêi·ªÉm b√™n tr√°i** thu·ªôc l·ªõp `0`, **ƒëi·ªÉm b√™n ph·∫£i** thu·ªôc l·ªõp `1`.
                """)


    with tab_load:
        with st.expander("**Ph√¢n chia d·ªØ li·ªáu**", expanded=True):    

            # Ki·ªÉm tra n·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c load
            if "train_images" in st.session_state:
                # L·∫•y d·ªØ li·ªáu t·ª´ session_state
                train_images = st.session_state.train_images
                train_labels = st.session_state.train_labels
                test_images = st.session_state.test_images
                test_labels = st.session_state.test_labels

                # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√†nh vector 1 chi·ªÅu
                X = np.concatenate((train_images, test_images), axis=0)  # G·ªôp to√†n b·ªô d·ªØ li·ªáu
                y = np.concatenate((train_labels, test_labels), axis=0)
                X = X.reshape(X.shape[0], -1)  # Chuy·ªÉn th√†nh vector 1 chi·ªÅu
                with mlflow.start_run():

                    # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn t·ª∑ l·ªá validation v√† test
                    test_size = st.slider("üîπ Ch·ªçn % t·ª∑ l·ªá t·∫≠p test", min_value=10, max_value=50, value=20, step=5) / 100
                    val_size = st.slider("üîπ Ch·ªçn % t·ª∑ l·ªá t·∫≠p validation (trong ph·∫ßn train)", min_value=10, max_value=50, value=20, step=5) / 100

                    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
                    val_size_adjusted = val_size / (1 - test_size)  # ƒêi·ªÅu ch·ªânh t·ª∑ l·ªá val cho ph·∫ßn c√≤n l·∫°i
                    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size_adjusted, random_state=42)

                    # T√≠nh t·ª∑ l·ªá th·ª±c t·∫ø c·ªßa t·ª´ng t·∫≠p
                    total_samples = X.shape[0]
                    test_percent = (X_test.shape[0] / total_samples) * 100
                    val_percent = (X_val.shape[0] / total_samples) * 100
                    train_percent = (X_train.shape[0] / total_samples) * 100
                st.write(f"üìä **T·ª∑ l·ªá ph√¢n chia**: Test={test_percent:.0f}%, Validation={val_percent:.0f}%, Train={train_percent:.0f}%")
                st.write("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† chia t√°ch.")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán: `{X_train.shape}`")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p validation: `{X_val.shape}`")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra: `{X_test.shape}`")
            else:
                st.error("üö® D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c n·∫°p. H√£y ƒë·∫£m b·∫£o `train_images`, `train_labels` v√† `test_images` ƒë√£ ƒë∆∞·ª£c t·∫£i tr∆∞·ªõc khi ch·∫°y.")



    # 3Ô∏è‚É£ HU·∫§N LUY·ªÜN M√î H√åNH
    with tab_preprocess:
        with st.expander("**Hu·∫•n luy·ªán m√¥ h√¨nh**", expanded=True):
            # L·ª±a ch·ªçn m√¥ h√¨nh
            model_option = st.radio("üîπ Ch·ªçn m√¥ h√¨nh hu·∫•n luy·ªán:", ("Decision Tree", "SVM"))
            if model_option == "Decision Tree":
                st.subheader("üå≥ Decision Tree Classifier")
                        
                        # L·ª±a ch·ªçn tham s·ªë cho Decision Tree
                # criterion = st.selectbox("Ch·ªçn ti√™u ch√≠ ph√¢n nh√°nh:", (["entropy"]))
                max_depth = st.slider("Ch·ªçn ƒë·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y:", min_value=1, max_value=20, value=5)
                st.session_state["dt_max_depth"] = max_depth
                n_folds = st.slider("Ch·ªçn s·ªë folds cho K-Fold Cross-Validation:", min_value=2, max_value=10, value=5)

                if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
                    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                        with mlflow.start_run():
                            # Kh·ªüi t·∫°o m√¥ h√¨nh Decision Tree
                            dt_model = DecisionTreeClassifier( max_depth=max_depth, random_state=42)

                            # Th·ª±c hi·ªán K-Fold Cross-Validation v·ªõi s·ªë folds do ng∆∞·ªùi d√πng ch·ªçn
                            kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
                            cv_scores = []

                            for train_index, val_index in kf.split(X_train):
                                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
                                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

                                # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n fold hi·ªán t·∫°i
                                dt_model.fit(X_train_fold, y_train_fold)
                                # D·ª± ƒëo√°n v√† t√≠nh ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p validation c·ªßa fold
                                y_val_pred_fold = dt_model.predict(X_val_fold)
                                fold_accuracy = accuracy_score(y_val_fold, y_val_pred_fold)
                                cv_scores.append(fold_accuracy)

                            # T√≠nh ƒë·ªô ch√≠nh x√°c trung b√¨nh t·ª´ cross-validation
                            mean_cv_accuracy = np.mean(cv_scores)
                            std_cv_accuracy = np.std(cv_scores)  # ƒê·ªô l·ªách chu·∫©n ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ·ªïn ƒë·ªãnh

                            # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n to√†n b·ªô X_train, y_train ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
                            dt_model.fit(X_train, y_train)
                            y_val_pred_dt = dt_model.predict(X_val)
                            accuracy_dt = accuracy_score(y_val, y_val_pred_dt)

                            # Ghi log v√†o MLflow
                            mlflow.log_param("model_type", "Decision Tree")
                        
                            mlflow.log_param("max_depth", max_depth)
                            mlflow.log_param("n_folds", n_folds)  # Ghi s·ªë folds do ng∆∞·ªùi d√πng ch·ªçn
                            mlflow.log_metric("mean_cv_accuracy", mean_cv_accuracy)
                            mlflow.log_metric("std_cv_accuracy", std_cv_accuracy)
                            mlflow.log_metric("accuracy", accuracy_dt)
                            mlflow.sklearn.log_model(dt_model, "decision_tree_model")

                            # L∆∞u v√†o session_state
                            st.session_state["selected_model_type"] = "Decision Tree"
                            st.session_state["trained_model"] = dt_model 
                            st.session_state["X_train"] = X_train 
                            st.session_state["dt_max_depth"] = max_depth
                            st.session_state["n_folds"] = n_folds 

                    
                            st.markdown("---") 
                            st.write(f"üîπM√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ ƒë√°nh gi√°: `{model_option}`")
                            st.write("üîπ Tham s·ªë m√¥ h√¨nh:")
                            st.write(f"- **ƒê·ªô s√¢u t·ªëi ƒëa**: `{max_depth}`")
                            st.write(f"- **S·ªë folds trong Cross-Validation**: `{n_folds}`")
                            st.write(f"‚úÖ **ƒê·ªô ch√≠nh x√°c trung b√¨nh t·ª´ K-Fold Cross-Validation ({n_folds} folds):** `{mean_cv_accuracy:.4f} ¬± {std_cv_accuracy:.4f}`")
                            st.write(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation:** `{accuracy_dt:.4f}`")
                            
                        mlflow.end_run()
            elif model_option == "SVM":
                st.subheader("üåÄ Support Vector Machine (SVM)")
                            
                            # L·ª±a ch·ªçn tham s·ªë cho SVM
                kernel = st.selectbox("Ch·ªçn kernel:", ["linear", "poly", "rbf", "sigmoid"])
                C = st.slider("Ch·ªçn gi√° tr·ªã C (ƒëi·ªÅu ch·ªânh m·ª©c ƒë·ªô regularization):", min_value=0.1, max_value=10.0, value=1.0)
                n_folds = st.slider("Ch·ªçn s·ªë folds cho K-Fold Cross-Validation:", min_value=2, max_value=10, value=5)
                if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
                    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                        with mlflow.start_run():
                            # Kh·ªüi t·∫°o m√¥ h√¨nh SVM
                            svm_model = SVC(kernel=kernel, C=C, random_state=42)

                            # Th·ª±c hi·ªán K-Fold Cross-Validation v·ªõi s·ªë folds do ng∆∞·ªùi d√πng ch·ªçn
                            kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
                            cv_scores = []

                            for train_index, val_index in kf.split(X_train):
                                X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
                                y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

                                # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n fold hi·ªán t·∫°i
                                svm_model.fit(X_train_fold, y_train_fold)
                                # D·ª± ƒëo√°n v√† t√≠nh ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p validation c·ªßa fold
                                y_val_pred_fold = svm_model.predict(X_val_fold)
                                fold_accuracy = accuracy_score(y_val_fold, y_val_pred_fold)
                                cv_scores.append(fold_accuracy)

                            # T√≠nh ƒë·ªô ch√≠nh x√°c trung b√¨nh t·ª´ cross-validation
                            mean_cv_accuracy = np.mean(cv_scores)
                            std_cv_accuracy = np.std(cv_scores)  # ƒê·ªô l·ªách chu·∫©n ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ·ªïn ƒë·ªãnh

                            # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n to√†n b·ªô X_train, y_train ƒë·ªÉ s·ª≠ d·ª•ng sau n√†y
                            svm_model.fit(X_train, y_train)
                            y_val_pred_svm = svm_model.predict(X_val)
                            accuracy_svm = accuracy_score(y_val, y_val_pred_svm)

                            # Ghi log v√†o MLflow
                            mlflow.log_param("model_type", "SVM")
                            mlflow.log_param("kernel", kernel)
                            mlflow.log_param("C_value", C)
                            mlflow.log_param("n_folds", n_folds)  # Ghi s·ªë folds do ng∆∞·ªùi d√πng ch·ªçn
                            mlflow.log_metric("mean_cv_accuracy", mean_cv_accuracy)
                            mlflow.log_metric("std_cv_accuracy", std_cv_accuracy)
                            mlflow.log_metric("accuracy", accuracy_svm)
                            mlflow.sklearn.log_model(svm_model, "svm_model")

                            # L∆∞u v√†o session_state
                            st.session_state["selected_model_type"] = "SVM"
                            st.session_state["trained_model"] = svm_model  
                            st.session_state["X_train"] = X_train
                            st.session_state["svm_kernel"] = kernel  # L∆∞u kernel v√†o session_state
                            st.session_state["svm_C"] = C  # L∆∞u C v√†o session_state
                            st.session_state["n_folds"] = n_folds

                            st.markdown("---") 
                            st.write(f"üîπM√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ ƒë√°nh gi√°: `{model_option}`")
                            kernel = st.session_state.get("svm_kernel", "linear")
                            C = st.session_state.get("svm_C", 1.0)
                            st.write("üîπ **Tham s·ªë m√¥ h√¨nh:**")
                            st.write(f"- Kernel: `{kernel}`")
                            st.write(f"- C (Regularization): `{C}`")
                            st.write(f"- **S·ªë folds trong Cross-Validation**: `{n_folds}`")
                            st.write(f"‚úÖ **ƒê·ªô ch√≠nh x√°c trung b√¨nh t·ª´ K-Fold Cross-Validation ({n_folds} folds):** `{mean_cv_accuracy:.4f} ¬± {std_cv_accuracy:.4f}`")
                            st.write(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation:** `{accuracy_svm:.4f}`")
                            
                        mlflow.end_run()

    with tab_demo:   
        with st.expander("**D·ª± ƒëo√°n k·∫øt qu·∫£**", expanded=True):
            st.write("**D·ª± ƒëo√°n tr√™n ·∫£nh do ng∆∞·ªùi d√πng t·∫£i l√™n**")

            # Ki·ªÉm tra xem m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† l∆∞u k·∫øt qu·∫£ ch∆∞a
            if "selected_model_type" not in st.session_state or "trained_model" not in st.session_state:
                st.warning("‚ö†Ô∏è Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n.")
            else:
                best_model_name = st.session_state.selected_model_type
                best_model = st.session_state.trained_model

                st.write(f"üéØ M√¥ h√¨nh ƒëang s·ª≠ d·ª•ng: `{best_model_name}`")
                # st.write(f"‚úÖ ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p ki·ªÉm tra: `{st.session_state.get('test_accuracy', 'N/A'):.4f}`")

                # L·∫•y c√°c tham s·ªë t·ª´ session_state ƒë·ªÉ hi·ªÉn th·ªã
                if best_model_name == "Decision Tree":
                    criterion = st.session_state.get("dt_criterion", "entropy")
                    max_depth = st.session_state.get("dt_max_depth", 5)  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† 5
                    n_folds = st.session_state.get("n_folds", 5)  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† 5
                    st.write("üîπ **Tham s·ªë m√¥ h√¨nh Decision Tree:**")
                    st.write(f"- **Ti√™u ch√≠ ph√¢n nh√°nh**: `{criterion}`")
                    st.write(f"- **ƒê·ªô s√¢u t·ªëi ƒëa**: `{max_depth}`")
                    st.write(f"- **S·ªë folds trong Cross-Validation**: `{n_folds}`")
                elif best_model_name == "SVM":
                    kernel = st.session_state.get("svm_kernel", "linear")
                    C = st.session_state.get("svm_C", 1.0)
                    n_folds = st.session_state.get("n_folds", 5)  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh l√† 5
                    st.write("üîπ **Tham s·ªë m√¥ h√¨nh SVM:**")
                    st.write(f"- **Kernel**: `{kernel}`")
                    st.write(f"- **C (Regularization)**: `{C}`")
                    st.write(f"- **S·ªë folds trong Cross-Validation**: `{n_folds}`")

                # Cho ph√©p ng∆∞·ªùi d√πng t·∫£i l√™n ·∫£nh
                uploaded_file = st.file_uploader("üìÇ Ch·ªçn m·ªôt ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n", type=["png", "jpg", "jpeg"])

                if uploaded_file is not None:
                    # ƒê·ªçc ·∫£nh t·ª´ t·ªáp t·∫£i l√™n
                    image = Image.open(uploaded_file).convert("L")  # Chuy·ªÉn sang ·∫£nh x√°m
                    image = np.array(image)

                    # Ki·ªÉm tra xem d·ªØ li·ªáu hu·∫•n luy·ªán ƒë√£ l∆∞u trong session_state hay ch∆∞a
                    if "X_train" in st.session_state:
                        X_train_shape = st.session_state["X_train"].shape[1]  # L·∫•y s·ªë ƒë·∫∑c tr∆∞ng t·ª´ t·∫≠p hu·∫•n luy·ªán

                        # Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc ph√π h·ª£p v·ªõi m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
                        image = cv2.resize(image, (28, 28))  # C·∫≠p nh·∫≠t k√≠ch th∆∞·ªõc theo d·ªØ li·ªáu ban ƒë·∫ßu
                        image = image.reshape(1, -1)  # Chuy·ªÉn v·ªÅ vector 1 chi·ªÅu

                        # ƒê·∫£m b·∫£o s·ªë chi·ªÅu ƒë√∫ng v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán
                        if image.shape[1] == X_train_shape:
                            prediction = best_model.predict(image)[0]

                            # Hi·ªÉn th·ªã ·∫£nh v√† k·∫øt qu·∫£ d·ª± ƒëo√°n
                            st.image(uploaded_file, caption="üì∑ ·∫¢nh b·∫°n ƒë√£ t·∫£i l√™n", use_container_width=True)
                            st.success(f"‚úÖ **D·ª± ƒëo√°n:** {prediction}")
                        else:
                            st.error(f"üö® ·∫¢nh kh√¥ng c√≥ s·ªë ƒë·∫∑c tr∆∞ng ƒë√∫ng ({image.shape[1]} thay v√¨ {X_train_shape}). H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o!")
                    else:
                        st.error("üö® D·ªØ li·ªáu hu·∫•n luy·ªán kh√¥ng t√¨m th·∫•y. H√£y hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n.")

    with tab_mlflow:
        st.header("Th√¥ng tin Hu·∫•n luy·ªán & MLflow UI")
        try:
            client = MlflowClient()
            experiment_name = "Classification"
    
            # Ki·ªÉm tra n·∫øu experiment ƒë√£ t·ªìn t·∫°i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment m·ªõi ƒë∆∞·ª£c t·∫°o v·ªõi ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"ƒêang s·ª≠ d·ª•ng experiment ID: {experiment_id}")
    
            mlflow.set_experiment(experiment_name)
    
            # Truy v·∫•n c√°c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])
    
            # 1) Ch·ªçn v√† ƒë·ªïi t√™n Run Name
            st.subheader("ƒê·ªïi t√™n Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                               for run in runs}
                selected_run_id_for_rename = st.selectbox("Ch·ªçn Run ƒë·ªÉ ƒë·ªïi t√™n:", 
                                                          options=list(run_options.keys()), 
                                                          format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi cho Run:", 
                                             value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("C·∫≠p nh·∫≠t t√™n Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ c·∫≠p nh·∫≠t t√™n Run th√†nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui l√≤ng nh·∫≠p t√™n m·ªõi cho Run.")
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log.")
    
            # 2) X√≥a Run
            st.subheader("Danh s√°ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                         options=list(run_options.keys()), 
                                                         format_func=lambda x: run_options[x])
                if st.button("X√≥a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ƒê√£ x√≥a Run {run_options[selected_run_id_to_delete]} th√†nh c√¥ng!")
                    st.experimental_rerun()  # T·ª± ƒë·ªông l√†m m·ªõi giao di·ªán
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë·ªÉ x√≥a.")
    
            # 3) Danh s√°ch c√°c th√≠ nghi·ªám
            st.subheader("Danh s√°ch c√°c Run ƒë√£ log")
            if runs:
                selected_run_id = st.selectbox("Ch·ªçn Run ƒë·ªÉ xem chi ti·∫øt:", 
                                               options=list(run_options.keys()), 
                                               format_func=lambda x: run_options[x])
    
                # 4) Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa Run ƒë∆∞·ª£c ch·ªçn
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
    
                st.markdown("### Tham s·ªë ƒë√£ log")
                st.json(selected_run.data.params)
    
                st.markdown("### Ch·ªâ s·ªë ƒë√£ log")
                metrics = {
                    "mean_cv_accuracy": selected_run.data.metrics.get("mean_cv_accuracy", "N/A"),
                    "std_cv_accuracy": selected_run.data.metrics.get("std_cv_accuracy", "N/A"),
                    "accuracy": selected_run.data.metrics.get("accuracy", "N/A"),
                    "model_type": selected_run.data.metrics.get("model_type", "N/A"),
                    "kernel": selected_run.data.metrics.get("kernel", "N/A"),
                    "C_value": selected_run.data.metrics.get("C_value", "N/A")
                

                }
                st.json(metrics)
    
                # 5) N√∫t b·∫•m m·ªü MLflow UI
                st.subheader("Truy c·∫≠p MLflow UI")
                mlflow_url = "https://dagshub.com/Dung2204/HMVPython.mlflow"
                if st.button("M·ªü MLflow UI"):
                    st.markdown(f'**[Click ƒë·ªÉ m·ªü MLflow UI]({mlflow_url})**')
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
    
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow: {e}")




if __name__ == "__main__":
    run_ClassificationMinst_app()
    # st.write(f"MLflow Tracking URI: {mlflow.get_tracking_uri()}")
    # print("üéØ Ki·ªÉm tra tr√™n DagsHub: https://dagshub.com/Dung2204/MINST.mlflow/")
    # # # cd "C:\Users\Dell\OneDrive\Pictures\Documents\Code\python\OpenCV\HMVPYTHON\App"
    # ClassificationMinst.
    



    ## thay v√¨ decision tree l√† gini v√† entropy th√¨ -> ch·ªâ c√≤n entropy v·ªõi ch·ªçn ƒë·ªô s√¢u c·ªßa c√¢y
    ## b·ªï sung th√™m Ch·ªçn s·ªë folds (KFold Cross-Validation) ·ªü c·∫£ 2 ph·∫ßn decsion tree v√† svms
    ## c·∫≠p nh·∫≠t l·∫°i ph·∫ßn demo , v√¨ n√≥ ƒëang kh√¥ng s·ª≠ d·ª•ng d·ªØ li·ªáu ·ªü ph·∫ßn hu·∫•n luy·ªán
  
